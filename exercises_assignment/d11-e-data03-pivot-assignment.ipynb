{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d5d808a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data: Pivoting Data\n",
    "\n",
    "*Purpose*: Data is easiest to use when it is *tidy*. In fact, grama is specifically designed to use tidy data. But not all data we'll encounter is tidy! To that end, in this exercise we'll learn how to tidy our data by *pivoting*.\n",
    "\n",
    "As a result of learning how to quickly *tidy* data, you'll vastly expand the set of datasets you can analyze. Rather than fighting with data, you'll be able to quickly wrangle and extract insights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909ea5",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aad34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline\n",
    "\n",
    "# For assertion\n",
    "from pandas.api.types import is_integer_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88cfce",
   "metadata": {},
   "source": [
    "# Tidy Data\n",
    "\n",
    "*Tidy Data* is a very simple---but *very powerful*---concept for structuring a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033dc500",
   "metadata": {},
   "source": [
    "![Stylized text providing an overview of Tidy Data. The top reads “Tidy data is a standard way of mapping the meaning of a dataset to its structure. - Hadley Wickham.” On the left reads “In tidy data: each variable forms a column; each observation forms a row; each cell is a single measurement.” There is an example table on the lower right with columns ‘id’, ‘name’ and ‘color’ with observations for different cats, illustrating tidy data structure.](./images/tidydata_1.jpg)\n",
    "Artwork by @allison_horst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728eabcf",
   "metadata": {},
   "source": [
    "## Tidy Data: Definition\n",
    "\n",
    "A tidy dataset has three properties:\n",
    "\n",
    "- each variable forms a column\n",
    "- each observation forms a row\n",
    "- each cell is a single measurement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c0cf5",
   "metadata": {},
   "source": [
    "As an example, the following dataset is tidy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n",
    "df_stang.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520b527",
   "metadata": {},
   "source": [
    "The observations are all measured material properties taken at a particular angle (with respect to the direction in which the specimens were rolled). Each column reports values for just one variable, each row corresponds to a single observation, and every cell reports just one measurement.\n",
    "\n",
    "However, the following form of the same dataset is *not* tidy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358cf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang_wide\n",
    "df_stang_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4c044",
   "metadata": {},
   "source": [
    "This dataset is *not* tidy: The angle of each measurement `00, 45, 90` is a variable, but these numerical values are expressed as column names. Put differently, some of the values are not in cells, but rather in the column names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17c6ce",
   "metadata": {},
   "source": [
    "## Why tidy data?\n",
    "\n",
    "Tidy data makes analysis *easier*. Putting our data in tidy form means we can use a *consistent* set of tools to work with *any* dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4171db2e",
   "metadata": {},
   "source": [
    "![On the left is a happy cute fuzzy monster holding a rectangular data frame with a tool that fits the data frame shape. On the workbench behind the monster are other data frames of similar rectangular shape, and neatly arranged tools that also look like they would fit those data frames. The workbench looks uncluttered and tidy. The text above the tidy workbench reads “When working with tidy data, we can use the same tools in similar ways for different datasets…” On the right is a cute monster looking very frustrated, using duct tape and other tools to haphazardly tie data tables together, each in a different way. The monster is in front of a messy, cluttered workbench. The text above the frustrated monster reads “...but working with untidy data often means reinventing the wheel with one-time approaches that are hard to iterate or reuse.”](./images/tidydata_3.jpg)\n",
    "Artwork by @allison_horst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eef413",
   "metadata": {},
   "source": [
    "Note that untidy data is not *bad* data; untidy data are simply harder to work with when doing data analysis. Data often come in untidy form when they are reported, say in a paper or a presentation. For instance, the wide form of the Stang et al. dataset can easily fit on one page:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ff8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stang_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238dc798",
   "metadata": {},
   "source": [
    "However, the tidy form of the same dataset is far less compact:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f20344",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f9182",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Let's practice identifying tidy and untidy data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575437c",
   "metadata": {},
   "source": [
    "### __q1__ Identify\n",
    "\n",
    "Inspect the following dataset; answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff8190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: No need to edit; run and inspect\n",
    "df_cases = gr.df_make(\n",
    "    country=[\"FR\", \"DE\", \"US\"],\n",
    "    year2011=[7000, 5800, 15000],\n",
    "    year2012=[6900, 6000, 14000],\n",
    "    year2013=[7000, 6200, 13000],\n",
    ")\n",
    "df_cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2715efa",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What are the *variables* in this dataset?\n",
    "  - (Your response here)\n",
    "- Is this dataset *tidy*? Why or why not?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980ee26e",
   "metadata": {},
   "source": [
    "### __q2__ Identify\n",
    "\n",
    "Inspect the following dataset; answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: No need to edit; run and inspect\n",
    "df_alloys1 = gr.df_make(\n",
    "    thick=[0.022, 0.022, 0.032, 0.032],\n",
    "    E_00=[10600, 10600, 10400, 10300],\n",
    "    mu_00=[0.321, 0.323, 0.329, 0.319],\n",
    "    E_45=[10700, 10500, 10400, 10500],\n",
    "    mu_45=[0.329, 0.331, 0.318, 0.326],\n",
    "    rep=[1, 2, 1, 2],\n",
    ")\n",
    "df_alloys1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746a679",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What are the *variables* in this dataset?\n",
    "  - (Your response here)\n",
    "- Is this dataset *tidy*? Why or why not?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63f0ce",
   "metadata": {},
   "source": [
    "### __q3__ Identify\n",
    "\n",
    "Inspect the following dataset; answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e62695",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: No need to edit; run and inspect\n",
    "df_alloys2 = gr.df_make(\n",
    "    thick=[0.022, 0.022, 0.032, 0.032],\n",
    "    var=[\"E\", \"mu\", \"E\", \"mu\"],\n",
    "    value=[10700, 0.321, 10500, 0.323],\n",
    "    rep=[1, 1, 2, 2],\n",
    "    angle=[0, 0, 0, 0],\n",
    ")\n",
    "df_alloys2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e582ea",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What are the *variables* in this dataset?\n",
    "  - (Your response here)\n",
    "- Is this dataset *tidy*? Why or why not?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b39b99",
   "metadata": {},
   "source": [
    "# Pivoting Data\n",
    "\n",
    "The untidy datasets above fail to be tidy because they have the wrong *shape*; we can tidy these datasets by *pivoting* the data. There are just two pivots we need to learn about: `tf_pivot_longer()` and `tf_pivot_wider()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b593c87",
   "metadata": {},
   "source": [
    "## Pivot Longer\n",
    "\n",
    "Let's take another look at the `df_cases` example dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599ee72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d277a5",
   "metadata": {},
   "source": [
    "This dataset is *too wide*; the column names `year2011,year2012,year2013` should really be numbers inside a single `year` column. We can *pivot longer* to move from a wide structure to a longer one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80882bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    df_cases\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"year2011\", \"year2012\", \"year2013\"],\n",
    "        names_to=\"year\",\n",
    "        values_to=\"count\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d4a14",
   "metadata": {},
   "source": [
    "Note what we had to provide as arguments to `gr.tf_pivot_longer()`:\n",
    "\n",
    "- `columns` specifies the columns to involve in the pivoting\n",
    "- `names_to` specifies what new column will contain the previous column names\n",
    "- `value_to` specifies what new column will contain the previous cell values\n",
    "\n",
    "Often, a pivot alone is not enough to fully clean a dataset; for instance, we would still need to remove the `year` string from each cell entry. However, we can do this much more easily once the data are pivoted into a longer format:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    df_cases\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"year2011\", \"year2012\", \"year2013\"],\n",
    "        names_to=\"year\",\n",
    "        values_to=\"count\",\n",
    "    )\n",
    "    >> gr.tf_mutate(year=gr.str_replace(DF.year, \"year\", \"\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada758b",
   "metadata": {},
   "source": [
    "### __q4__ Pivot the data\n",
    "\n",
    "Pivot the dataset `df_alloys1` to place each of `E_00, mu_00, E_45, mu_45` as values in a new `variable` column, and move the original values to a new `value` column. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a22d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Tidy the data, make sure to provide `variable` and `value` columns\n",
    "df_res1 = (\n",
    "    df_alloys1\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "print(df_res1)\n",
    "\n",
    "assert \\\n",
    "    {\"thick\", \"rep\", \"variable\", \"value\"} == set(df_res1.columns), \\\n",
    "    'columns of df_res1 are not [\"thick\", \"rep\", \"variable\", \"value\"]'\n",
    "\n",
    "assert \\\n",
    "    {\"E_00\", \"mu_00\", \"E_45\", \"mu_45\"} == set(df_res1.variable), \\\n",
    "    'Entries in df_res1.variable are incorrect'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe70b93",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Is this dataset tidy? Why or why not?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40147b",
   "metadata": {},
   "source": [
    "### Using selection helpers\n",
    "\n",
    "One useful feature of `gr.tf_pivot_longer()` is that we can use [selection helpers](https://zdelrosario.github.io/evc-course/exercises_solution/d02-e-data01-isolate-solution.html#selection-helpers) to choose which columns to use in a pivot. This can save us a lot of typing, and allows us to write code that can react to multiple different datasets. Let's practice using selection helpers by re-doing the previous task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bad57bb",
   "metadata": {},
   "source": [
    "### __q5__ Simplify with selection helpers\n",
    "\n",
    "Use a single [selection helper](https://zdelrosario.github.io/evc-course/exercises_solution/d02-e-data01-isolate-solution.html#selection-helpers) to simplify the `columns` argument to `gr.tf_pivot_longer()`.\n",
    "\n",
    "*Hint*: There are multiple ways to do this: The string `\"E|mu\"` will `match` the strings `\"E\"` or `\"mu\"`. The string `\"\\\\d+\"` will `match` *any string of consecutive digits*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Replace the `columns` argument with a selection helper\n",
    "df_simplified = (\n",
    "    df_alloys1\n",
    "    >> gr.tf_pivot_longer(\n",
    "        # columns=[\"E_00\", \"mu_00\", \"E_45\", \"mu_45\"],\n",
    "\n",
    "        names_to=\"variable\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "print(df_simplified)\n",
    "\n",
    "assert \\\n",
    "    {\"thick\", \"rep\", \"variable\", \"value\"} == set(df_simplified.columns), \\\n",
    "    'columns of df_res1 are not [\"thick\", \"rep\", \"variable\", \"value\"]'\n",
    "\n",
    "assert \\\n",
    "    {\"E_00\", \"mu_00\", \"E_45\", \"mu_45\"} == set(df_simplified.variable), \\\n",
    "    'Entries in df_res1.variable are incorrect'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbb8869",
   "metadata": {},
   "source": [
    "## Pivot Wider\n",
    "\n",
    "Just as a dataset can be \"too wide\", it can also be \"too long.\" In this case, we can use `gr.tf_pivot_wider()`. Let's look at an illustrative example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4866eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_long = gr.df_make(\n",
    "    variable=[\"x\", \"y\", \"f\", \"x\", \"y\", \"f\"],\n",
    "    value=[0, 0, 1, 0, 1, 0],\n",
    "    observation=[0, 0, 0, 1, 1, 1],\n",
    ")\n",
    "df_long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd4106",
   "metadata": {},
   "source": [
    "Here, the `value` column has mixed variables; values of `x`, `y`, and `f` comingle in the `value` column. Really we should have the *columns* `x`, `y`, and `f`: In this sense the data is *too long*. Let's pivot wider to tidy the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cd542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    df_long\n",
    "    >> gr.tf_pivot_wider(\n",
    "        names_from=\"variable\",\n",
    "        values_from=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9803c915",
   "metadata": {},
   "source": [
    "Note that we had to provide just two inputs to `gr.tf_pivot_wider()`:\n",
    "\n",
    "- `names_from` specifies which column will provide the new column names\n",
    "- `value_from` specifies which column will provide the new column values\n",
    "\n",
    "Let's get some practice!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71af49ce",
   "metadata": {},
   "source": [
    "### __q6__ Pivot the data\n",
    "\n",
    "Pivot the dataset `df_alloys2` to provide `E` and `mu` as columns in `df_res2`. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54582b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Pivot the dataset wider\n",
    "df_res2 = (\n",
    "    df_alloys2\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use the following to check your work\n",
    "print(df_res2)\n",
    "\n",
    "assert \\\n",
    "    {\"thick\", \"rep\", \"angle\", \"E\", \"mu\"} == set(df_res2.columns), \\\n",
    "    'df_res2 does not have the columns [\"thick\", \"rep\", \"angle\", \"E\", \"mu\"]'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6b1a1",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Is this dataset tidy? Why or why not?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554c148",
   "metadata": {},
   "source": [
    "### Warning: No observation identifier\n",
    "\n",
    "While the arguments to `gr.tf_pivot_wider()` only target two columns, we *do* need to think carefully about what other columns are in the dataset. It is important that the other columns help identify which values are associated with the same observation---the easiest way to do this is with some sort of observation identifier column.\n",
    "\n",
    "Let's take a look at what happens when we *do not* have a way to associate values with the same observation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c9709",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    gr.df_make(\n",
    "        variable=[\"x\", \"y\", \"f\", \"x\", \"y\", \"f\"],\n",
    "        value=[0, 0, 1, 0, 1, 0],\n",
    "        # observation=[0, 0, 0, 1, 1, 1], # Remove the observation identifier\n",
    "    )\n",
    "    >> gr.tf_pivot_wider(\n",
    "        names_from=\"variable\",\n",
    "        values_from=\"value\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850754d2",
   "metadata": {},
   "source": [
    "Note that `gr.tf_pivot_wider()` placed all of the values in the \"correct\" column, but filled all over column values with `NaN`s. If you get strange behavior with `gr.tf_pivot_wider()`, you should think about whether you are providing the information necessary to associate common values with the same observation. We'll learn more about this in the next exercise.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
