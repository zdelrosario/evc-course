{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0192c2b7",
   "metadata": {},
   "source": [
    "# Stats: Distributions\n",
    "\n",
    "*Purpose*: We will use distributions to model uncertain quantities. Distributions (and densities, random variables) are useful mathematical objects, but we will need to understand their properties to use them as effective models. This exercise is about distributions and their fundamental properties: In a future exercise (`e-grama06-fit-univar`) we will discuss how to model real quantities with distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d186e",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36feecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "import numpy as np\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536e8c2",
   "metadata": {},
   "source": [
    "# Motivation: Modeling Uncertainty\n",
    "\n",
    "Before we discuss distributions, let's first talk about *why* distributions are necessary and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d2cd3",
   "metadata": {},
   "source": [
    "## To Model Variability\n",
    "\n",
    "Many real physical quantities exhibit *variability*; that is, different instances of \"the same\" quantity take different numerical values. This includes things like part geometry (tolerances), a person's height and weight, and even material properties. Let's look at a specific dataset of die cast aluminum material properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eacb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "from grama.data import df_shewhart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70ed557",
   "metadata": {},
   "source": [
    "If we inspect the `tensile_strength` values, we can see that they are quite variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_shewhart\n",
    "    >> gr.ggplot(gr.aes(\"tensile_strength\"))\n",
    "    + gr.geom_histogram()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f83532",
   "metadata": {},
   "source": [
    "In order to design in the presence of this variability, we need a way to represent this variability in a quantitative fashion. Distributions offer one way to quantitatively describe variability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174be184",
   "metadata": {},
   "source": [
    "## To Summarize Data\n",
    "\n",
    "A distribution is one way to *summarize* a dataset. Rather than using a (potentially large) dataset to describe a variable quantity, we can use a distribution.\n",
    "\n",
    "Fitting a lognormal distribution allows us to summarize the variability in `tensile_strength`. The following code fits a lognormal distribution to the `tensile_strength` data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deafdca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "# Fit a lognormal distribution\n",
    "mg_tensile_strength = gr.marg_fit(\n",
    "    \"lognorm\",\n",
    "    df_shewhart.tensile_strength,\n",
    "    floc=0,\n",
    ")\n",
    "# Show a summary\n",
    "mg_tensile_strength"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc709a",
   "metadata": {},
   "source": [
    "The distribution is defined in terms of a handful of *parameters*---scalar values that affect the quantitative properties of the distribution.\n",
    "\n",
    "When we compare the fitted distribution against the data, we can see that the fitted distribution is in the same location and has the same width as the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c051f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "# Visualize the density against the data\n",
    "(\n",
    "    df_shewhart\n",
    "    >> gr.ggplot(gr.aes(\"tensile_strength\"))\n",
    "    + gr.geom_histogram(gr.aes(y=gr.after_stat(\"density\")))\n",
    "    + gr.geom_line(\n",
    "        data=gr.df_make(tensile_strength=gr.linspace(20e3, 45e3, 100))\n",
    "        >> gr.tf_mutate(d=mg_tensile_strength.d(DF.tensile_strength)),\n",
    "        mapping=gr.aes(y=\"d\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a139695",
   "metadata": {},
   "source": [
    "## To Make Assumptions Explicit\n",
    "\n",
    "Selecting a distribtion helps us make assumptions about an uncertain quantity explicit. For instance, are we assuming that values are strictly bounded between low and high values? Or are there no bounds? \n",
    "\n",
    "For example, a normal distribution can take all values between $-\\infty$ and $+\\infty$, while a beta distribution has a finite width. The following visual compares the two distribution shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9c40e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "# Normal is unbounded\n",
    "mg_norm = gr.marg_mom(\"norm\", mean=0, sd=1)\n",
    "# Beta is strictly bounded\n",
    "mg_beta = gr.marg_mom(\"beta\", mean=0, sd=1, skew=0, kurt=2)\n",
    "\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(-3, +3, 20))\n",
    "    >> gr.tf_mutate(\n",
    "        d_norm=mg_norm.d(DF.x),\n",
    "        d_beta=mg_beta.d(DF.x),\n",
    "    )\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"d_norm\", \"d_beta\"],\n",
    "        names_to=[\".value\", \"distribution\"],\n",
    "        names_sep=\"_\",\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\", color=\"distribution\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.theme_minimal()\n",
    "    + gr.labs(\n",
    "        x=\"Value\",\n",
    "        y=\"Density\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6af25f",
   "metadata": {},
   "source": [
    "# Distribution Fundamentals\n",
    "\n",
    "*Note*: In this exercise, to keep things simple, we will focus on distributions for *continuous* variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0dca69",
   "metadata": {},
   "source": [
    "## What a distribution represents\n",
    "\n",
    "*Fundamentally*, a distribution describes an uncertain value *in a quantitative fashion*. Rather than simply saying \"I don't know what value this is,\" with a distribution we can express the fact that some values are more *likely* than others.\n",
    "\n",
    "Distributions are particularly useful because they free us from \"just\" picking a single number. With a distribution we can get a lot more nuanced in our description of uncertain quantities. This exercise is all about using concepts about distributions to represent uncertain quantities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e6fbe",
   "metadata": {},
   "source": [
    "## Random variables\n",
    "\n",
    "Clearly `tensile_strength` does not take a single value; therefore, we should think of `tensile_strength` as a *random variable*. A random variable is a mathematical object that we can use to model an uncertain quantity. Unlike a *deterministic variable* that has one fixed value (say $x = 1$), a random variable can take a different value each time we *observe* it. For instance, if $X$ were a random variable, and we used $X_i$ to denote the value that occurs on the $i$-th observation, then we might see a sequence like\n",
    "\n",
    "$$X_1 = 1, X_2 = -3, X_3 = 1, X_4 = 5, \\dots$$\n",
    "\n",
    "What counts as an *observation* depends on what we are using the random variable to model. Essentially, an observation is an occurrence that gives us the potential to \"see\" a new value. \n",
    "\n",
    "Let's take a look at the `tensile_strength` example to get a better sense of these ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a618c3",
   "metadata": {},
   "source": [
    "For the `tensile_strength`, we saw a sequence of different values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e9196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    df_shewhart\n",
    "    >> gr.tf_head(4)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa33cf6",
   "metadata": {},
   "source": [
    "Every time we manufacture a new part, we perform a sequence of manufacturing steps that work together to \"lock in\" a particular value of `tensile_strength`. Those individual steps tend to go slightly differently each time we make a part (e.g. an operator calls in sick one day, we get a slightly more dense batch of raw material, it's a particularly hot summer day, etc.), so we end up with different properties in each part.\n",
    "\n",
    "Given the complicated realities of manfacturing, it makes sense to think of an *observation* as being one complete run of the manufacturing process that generates a particular part with its own `tensile_strength`. This is what the `specimen` column in `df_shewhart` refers to; a unique identifier tracking individual runs of the complete manufacturing process, resulting in a unique part.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a65f6",
   "metadata": {},
   "source": [
    "```{admonition} Nomenclature: A *realization* is like a single roll of a die\n",
    "Some nomenclature: When we talk about random quantities, we use the term *realization* (or *observation*) to refer to a single event that yields a random value, according to a particular distribution. For instance, a single manufactured part will have a realized strength value. If we take multiple realizations, we will tend to see different values. For instance, we saw a large amount of variability among the realized `tensile_strength` values above.\n",
    "\n",
    "A single realization tells us very little about how the distribution tends to behave, but a set of realizations (a *sample*) will give us a sense of how the random values tend to behave *collectively*. A distribution is a way to model that collective behavior.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0333927",
   "metadata": {},
   "source": [
    "**A distribution defines a random variable**. We say that a random variable $X$ is *distributed according to* a particular distribution $\\rho$, and we express the same statement mathematically as\n",
    "\n",
    "$$X \\sim \\rho.$$\n",
    "\n",
    "One way to represent a distribution is with a *density function*. The following plot displays the density for a normal distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92dcbf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "# This visualizes a density function\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(-3, +3, 200))\n",
    "    >> gr.tf_mutate(d=mg_norm.d(DF.x))\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.theme_minimal()\n",
    "    + gr.labs(\n",
    "        x=\"Value\",\n",
    "        y=\"Density\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f0a4c",
   "metadata": {},
   "source": [
    "The `Value` pictured here corresponds to all of the potential values that the random variable can take, while the `Density` quantitatively describes how likely (or unlikely) each of those values are. A value with a higher density will tend to occur more often. Density functions tend to \"fall off\" towards zero as we move towards more extreme values; these lower regions of the density are called \"tails\" of the distribution. The smallest values are associated with the \"lower\" or \"left\" tail, while the largest values are associated with the \"upper\" or \"right\" tail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22feede4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __q1__ Define a distribution\n",
    "\n",
    "Use the grama helper function `gr.marg_mom()` to define a distribution in terms of its *moments*. Fit a normal `\"norm\"` distribution with a mean of `1` and a standard deviation of `0.3`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcaa13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Define a normal distribution\n",
    "mg_norm = None # Define the distribution here\n",
    "\n",
    "\n",
    "## NOTE: No need to edit; this will plot your distribution\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(0, 3, 100))\n",
    "    >> gr.tf_mutate(d=mg_norm.d(DF.x))\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\"))\n",
    "    + gr.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a5d08",
   "metadata": {},
   "source": [
    "### __q2__ Check your distribution's summary\n",
    "\n",
    "Print the distribution's summary by simply \"executing\" the distribution (like you would with a DataFrame or grama model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Print the summary of mg_norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182bcef",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What mean does your distribution have?\n",
    "  - (Your response here)\n",
    "- What value of *skewness* does your distribution have?\n",
    "  - (Your response here)\n",
    "- What value of *kurtosis* does your distribution have?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b605190d",
   "metadata": {},
   "source": [
    "## Moments\n",
    "\n",
    "The summary of a distribution reports a few of its *moments*. These moments tell us different \"facts\" about the distribution:\n",
    "\n",
    "| Moment | Meaning |\n",
    "|--------|---------|\n",
    "| Mean   | Location |\n",
    "| Standard deviation | Width |\n",
    "| Skewness | Left- or right-lopsidedness |\n",
    "| Kurtosis | Tendency to produce extreme (large) values |\n",
    "\n",
    "Note that the distribution summary also reports the *coefficient of variation* (COV), which is a normalized version of the standard deviation (`COV = sd / mean`).\n",
    "\n",
    "The next few exercises will help you recognize how different moment values affect a distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab13f6",
   "metadata": {},
   "source": [
    "### __q3__ Compare different means\n",
    "\n",
    "Inspect the following distribution summaries and the plot. Answer the questions under *obervations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3387f620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; this will plot and compare two distributions\n",
    "mg_lo = gr.marg_mom(\"norm\", mean=-1, sd=0.5)\n",
    "mg_hi = gr.marg_mom(\"norm\", mean=+1, sd=0.5)\n",
    "\n",
    "## Print the summaries\n",
    "print(mg_lo)\n",
    "print(mg_hi)\n",
    "\n",
    "## Visualize the distributions\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(-3, 3, 100))\n",
    "    >> gr.tf_mutate(\n",
    "        d_lo=mg_lo.d(DF.x),\n",
    "        d_hi=mg_hi.d(DF.x),\n",
    "    )\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"d_lo\", \"d_hi\"],\n",
    "        names_to=[\".value\", \"distribution\"],\n",
    "        names_sep=\"_\",\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\", color=\"distribution\"))\n",
    "    + gr.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f16eac",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What is the mean (`mean`) of the `lo` distribution? How does that compare with the `mean` of the `hi` distribution?\n",
    "  - (Your response here)\n",
    "- The mean is a measure of the \"location\" of a distribution: In your own words, how does the `lo` distribution compare with the `hi` distribution?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e847f",
   "metadata": {},
   "source": [
    "### __q4__ Compare different standard deviations\n",
    "\n",
    "Inspect the following distribution summaries and the plot. Answer the questions under *obervations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778343ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; this will plot and compare distributions\n",
    "mg_narrow = gr.marg_mom(\"norm\", mean=0, sd=0.5)\n",
    "mg_wide = gr.marg_mom(\"norm\", mean=0, sd=1.0)\n",
    "\n",
    "## Print the summaries\n",
    "print(mg_narrow)\n",
    "print(mg_wide)\n",
    "\n",
    "## Visualize the distributions\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(-3, 3, 100))\n",
    "    >> gr.tf_mutate(\n",
    "        d_narrow=mg_narrow.d(DF.x),\n",
    "        d_wide=mg_wide.d(DF.x),\n",
    "    )\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"d_narrow\", \"d_wide\"],\n",
    "        names_to=[\".value\", \"distribution\"],\n",
    "        names_sep=\"_\",\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\", color=\"distribution\"))\n",
    "    + gr.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0250db2f",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What is the standard deviation (`sd`) of the `narrow` distribution? How does that compare with the `sd` of the `wide` distribution?\n",
    "  - (Your response here)\n",
    "- Standard deviation is a measure of \"width\" of a distribution: In your own words, how does the `wide` distribution compare with the `narrow` distribution?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e00c6",
   "metadata": {},
   "source": [
    "### __q5__ Compare different skewnesses\n",
    "\n",
    "Inspect the following distribution summaries and the plot. Answer the questions under *obervations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31589235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; this will plot and compare distributions\n",
    "mg_lognorm = gr.marg_mom(\"lognorm\", mean=1, sd=0.5, floc=0)\n",
    "\n",
    "## Print the summaries\n",
    "print(mg_norm)\n",
    "print(mg_lognorm)\n",
    "\n",
    "## Visualize the distributions\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(0, 3, 100))\n",
    "    >> gr.tf_mutate(\n",
    "        d_norm=mg_norm.d(DF.x),\n",
    "        d_lognorm=mg_lognorm.d(DF.x),\n",
    "    )\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"d_norm\", \"d_lognorm\"],\n",
    "        names_to=[\".value\", \"distribution\"],\n",
    "        names_sep=\"_\",\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\", color=\"distribution\"))\n",
    "    + gr.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f64bd",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What is the `skew.` of the `norm` distribution? How does that compare with the `skew` of the `lognorm` distribution?\n",
    "  - (Your response here)\n",
    "- Skewness is related to asymmetry of a distribution: In your own words, how is the lognormal distribution above asymmetric?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec2802",
   "metadata": {},
   "source": [
    "## Simulating values\n",
    "\n",
    "With a distribution, we can draw realizations in to generate a synthetic dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad2760c",
   "metadata": {},
   "source": [
    "### __q6__ *Draw* random values from your distribution\n",
    "\n",
    "Use the `Marginal.r(n)` method to *draw* `1000` random values from your distribution. Play with the sample size `n`, and answer the questions under *observations* below.\n",
    "\n",
    "*Hint*: A *method* is a function that you invoke using dot notation. If the marginal were named `mg`, then you could call the random value method via `mg.r(1000)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3c2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Draw 1000 random values from mg_norm\n",
    "X = None # TODO: Replace with 1000 random values\n",
    "\n",
    "\n",
    "## NOTE: No need to edit; use this to check your answer\n",
    "(\n",
    "    gr.df_make(x=X)\n",
    "    >> gr.ggplot(gr.aes(\"x\"))\n",
    "    + gr.geom_histogram(bins=30, mapping=gr.aes(y=\"stat(density)\"))\n",
    "    + gr.geom_line(\n",
    "        data=gr.df_make(x=gr.linspace(0, 2, 100))\n",
    "        >> gr.tf_mutate(d=mg_norm.d(DF.x)),\n",
    "        mapping=gr.aes(y=\"d\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62c85d1",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Set `n` to a small value (say `n=100`). How well does the histogram match the density?\n",
    "  - (Your response here)\n",
    "- What value of `n` is necessary for the histogram to resemble the density?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af581975",
   "metadata": {},
   "source": [
    "## Estimating the Mean\n",
    "\n",
    "The average of multiple realizations $X_i \\sim \\rho$ is called the *sample mean*\n",
    "\n",
    "$$\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i.$$\n",
    "\n",
    "The true mean of a distribution is called the *expectation* $\\mathbb{E}[X]$. The sample mean will tend to converge to the true mean as the number of realizations $n$ increases\n",
    "\n",
    "$$\\lim_{n\\to\\infty} \\frac{1}{n} \\sum_{i=1}^n X_i = \\mathbb{E}[X].$$\n",
    "\n",
    "However, when $n < \\infty$, the sample mean will tend to be different from the true mean of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75daab",
   "metadata": {},
   "source": [
    "### __q7__ Estimate a (sample) mean\n",
    "\n",
    "Complete the following code to compute the sample mean. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Compute the sample mean\n",
    "# NOTE: No need to edit; this will report the true mean\n",
    "print(mg_norm)\n",
    "\n",
    "(\n",
    "    gr.df_make(x=mg_norm.r(100))\n",
    "    ## TODO: Compute the sample mean\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33dca0",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- How does the sample mean compare with the true mean of your distribution `mg_norm`?\n",
    "  - (Your response here)\n",
    "- What might account for this difference?\n",
    "  - (Your response here)\n",
    "- Re-run the cell; do you get an identical value?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f52b82",
   "metadata": {},
   "source": [
    "```{admonition} The sample mean is a random variable\n",
    "Noting that the sample mean will tend to be different from the true mean highlights the essence of estimation with limited data: The sample mean is itself a random quantity.\n",
    "\n",
    "Note that the sample mean (and other estimated quantities) tend to exhibit *erroneous variability*; there is some true fixed value for the mean, and we see variability only because we have collected a limited amount of data. Increasing our sample size will tend to reduce this variability. Since this uncertainty is due to sampling, it is also called *sampling uncertainty*.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c22c73",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "Probability is the area under the density curve, within a set that you specify. Thus probability is associated with both a set $A$ and a random variable $X$. The set $A$ is chosen to correspond to an *event* of interest.\n",
    "\n",
    "For instance, if we were interested in the probability of the event $A = \\{0.5 <= X <= 0.7\\}$, the following area would be the probability:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "df_tmp = (\n",
    "    gr.df_make(x=gr.linspace(0, 2, 100))\n",
    "    >> gr.tf_mutate(d=mg_norm.d(DF.x))\n",
    ")\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.geom_ribbon(\n",
    "        data=df_tmp\n",
    "        >> gr.tf_filter(0.5 <= DF.x, DF.x <= 0.7),\n",
    "        mapping=gr.aes(ymin=0, ymax=\"d\"),\n",
    "        fill=\"salmon\",\n",
    "        color=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e5766",
   "metadata": {},
   "source": [
    "Note that probability is associated with a *set*---a range of values---not just a single value. Note that the area under the curve for a single value would have zero width, hence zero probability! \n",
    "\n",
    "The following pictures the case where $\\{X = 1\\}$, an event with just one value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c52ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "df_tmp = (\n",
    "    gr.df_make(x=gr.linspace(0, 2, 101))\n",
    "    >> gr.tf_mutate(d=mg_norm.d(DF.x))\n",
    ")\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.geom_segment(\n",
    "        data=df_tmp\n",
    "        >> gr.tf_filter(DF.x == gr.median(DF.x)),\n",
    "        mapping=gr.aes(xend=\"x\", yend=0),\n",
    "        color=\"salmon\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dcefd8",
   "metadata": {},
   "source": [
    "A more mathematical definition for probability is in terms of the expectation\n",
    "\n",
    "$$\\mathbb{P}[X \\in A] = \\mathbb{E}[1(X \\in A)]$$\n",
    "\n",
    "where $1(X \\in A)$ is the *indicator function*, which is just a compact way of tracking whether or not a point lands in the set $A$. The symbol $\\in$ just means \"inside a set\"; for example, $1 \\in \\{1, 2, 3\\}$, but $0 \\not\\in \\{1, 2, 3\\}$.\n",
    "\n",
    "The indicator function takes values $1,0$ depending on whether or not a value $X$ lands inside the set $A$.\n",
    "\n",
    "$$1(X \\in A) = \\left\\{\\begin{array}{cc} 1 & \\text{ if }X \\in A \\\\ 0 & \\text{ otherwise}\\end{array}\\right.$$\n",
    "\n",
    "This expectation definition is not just math for its own sake; this expectation of the indicator definition is **easy to translate into computer code**. We can use the sample mean of an indicator to estimate a probability\n",
    "\n",
    "$$\\mathbb{P}[X \\in A] \\approx \\frac{1}{n} \\sum_{i=1}^n 1(X_i \\in A).$$\n",
    "\n",
    "You will use this expression in the next tasks to approximate a probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884584f1",
   "metadata": {},
   "source": [
    "### __q8__ Compute an indicator\n",
    "\n",
    "Compute an indicator for the event $A = \\{X \\leq +1\\}$.\n",
    "\n",
    "*Hint*: Comparison operators like `<`, `>`, `<=`, `>=`, and `==` return boolean values `True` and `False`. However, python also treats these as numerical values, where `True == 1` and `False == 0`. This means you can use a simple comparison to compute an indicator value!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Compute an indicator for the event where x <= 1\n",
    "df_ind = (\n",
    "    gr.df_make(x=mg_norm.r(100))\n",
    "    >> gr.tf_mutate(\n",
    "    ## Compute the indicator function, call it `ind`\n",
    "        # ind=???\n",
    "\n",
    "    )\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    \"ind\" in df_ind.columns, \\\n",
    "    \"The result df_ind does not have an indicator column `ind`\"\n",
    "\n",
    "assert \\\n",
    "    (all(df_ind.ind == (df_ind.x <= 1))), \\\n",
    "    \"Your indicator column `ind` is incorrect.\"\n",
    "\n",
    "df_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661004a7",
   "metadata": {},
   "source": [
    "### __q9__ Estimate a probability\n",
    "\n",
    "Use the definition of probability along with your indicator value to approximate the probability that $X \\leq 1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Estimate the probability; call that column `pr`\n",
    "df_pr = (\n",
    "    df_ind\n",
    "    ## TODO: Estimate the probability using the indicator value `ind`\n",
    "\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    \"pr\" in df_pr.columns, \\\n",
    "    \"The result df_pr does not have the column `pr`\"\n",
    "\n",
    "assert \\\n",
    "    df_pr.pr.values[0] == df_ind.ind.mean(), \\\n",
    "    \"The value of df_pr.pr is incorrect\"\n",
    "\n",
    "df_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a30553",
   "metadata": {},
   "source": [
    "## Probability of Failure\n",
    "\n",
    "Probability is useful as a quantitative measure of a design's performance. For example, reliability engineers strive to produce designs that have a low *probability of failure*. This is important for safety-critical applications, such as in the design of buildings, bridges, or aircraft.\n",
    "\n",
    "To use probability to describe failure, we need to define an event $A$ that corresponds to failure for the system we are studying. For example, with the `tensile_strength` of an alloy, we can say failure occurs when the applied stress is greater than the strength. Rendered mathematically, this is the event\n",
    "\n",
    "$$A_{\\text{failure}} = \\{\\sigma_{\\text{strength}} \\leq \\sigma_{\\text{applied}}\\}.$$\n",
    "\n",
    "The probability of failure is then\n",
    "\n",
    "$$\\text{POF} = \\mathbb{P}[A_{\\text{failure}}].$$\n",
    "\n",
    "We can approximate the probability of failure of a part if we know the applied stress and have a dataset of `tensile_strength` values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9a1ba",
   "metadata": {},
   "source": [
    "### __q10__ Estimate a probability of failure\n",
    "\n",
    "Suppose the applied stress is $\\sigma_{\\text{applied}} = 25 \\times 10^3$ psi. Estimate the probability of failure of a part following the distribution of `tensile_strength` in the `df_shewhart` dataset. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf682aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Estimate the probability of failure associated with the applied stress above\n",
    "## provide this as the column `pof`\n",
    "df_pof = (\n",
    "    df_shewhart\n",
    "    ## TODO: Estimate the probability of failure as `pof`\n",
    "\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    \"pof\" in df_pof.columns, \\\n",
    "    \"The result df_pof does not have the column `pof`\"\n",
    "\n",
    "assert \\\n",
    "    abs(df_pof.pof.values[0] - 0.05) < 1e-3, \\\n",
    "    \"The value of df_pof.pof is incorrect\"\n",
    "\n",
    "df_pof\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815607a8",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What probability of failure `pof` did you estimate?\n",
    "  - (Your response here)\n",
    "- Is your value `pof` the *true* probability of failure? Why or why not?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434dd47f",
   "metadata": {},
   "source": [
    "## Quantiles\n",
    "\n",
    "Quantiles \"turn around\" the idea of probability. With probability we start with a set $A$ and arrive at a probability value $p$. With a *quantile* we start with a probability value $p$ and arrive at a set $A$ that is below a single value $q$; that is $A = \\{X \\leq q\\}$.\n",
    "\n",
    "For instance, for a normal distribution the `0.50` quantile is the value $q$ where 50% of the probability lies below that value; this will be the middle of the distribution, which happens to be the mean:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6110486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "# Compute the 0.50 quantile\n",
    "q_mid = mg_norm.q(0.50)\n",
    "\n",
    "# Visualize\n",
    "df_tmp = (\n",
    "    gr.df_make(x=gr.linspace(0, 2, 100))\n",
    "    >> gr.tf_mutate(d=mg_norm.d(DF.x))\n",
    ")\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.geom_ribbon(\n",
    "        data=df_tmp\n",
    "        >> gr.tf_filter(0.0 <= DF.x, DF.x <= q_mid),\n",
    "        mapping=gr.aes(ymin=0, ymax=\"d\"),\n",
    "        fill=\"salmon\",\n",
    "        color=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0de850",
   "metadata": {},
   "source": [
    "However, quantiles allow us to target values other than the mean. For instance, we could seek a moderately low value by targeting the `0.25` quantile, which will be the point where 25% of the probability is below the value $q$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec7078",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "# Compute the 0.25 quantile\n",
    "q_lo = mg_norm.q(0.25)\n",
    "\n",
    "# Visualize\n",
    "df_tmp = (\n",
    "    gr.df_make(x=gr.linspace(0, 2, 200))\n",
    "    >> gr.tf_mutate(d=mg_norm.d(DF.x))\n",
    ")\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"d\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.geom_ribbon(\n",
    "        data=df_tmp\n",
    "        >> gr.tf_filter(0.0 <= DF.x, DF.x <= q_lo),\n",
    "        mapping=gr.aes(ymin=0, ymax=\"d\"),\n",
    "        fill=\"salmon\",\n",
    "        color=None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc5bd3",
   "metadata": {},
   "source": [
    "As with the sample mean and a sample probability, we can compute sample quantiles from a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ad8e6",
   "metadata": {},
   "source": [
    "### __q11__ Compute sample quantiles\n",
    "\n",
    "Use the quantile method `q()` to compute the `0.10` and `0.50` quantiles of the `mg_norm` distribution. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Compute the exact 0.10 and 0.50 quantiles of mg_norm\n",
    "q_10 = None # Compute the 0.10 quantile of mg_norm\n",
    "q_50 = None # Compute the 0.50 quantile of mg_norm\n",
    "\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "# This compute sample quantiles\n",
    "(\n",
    "    gr.df_make(x=mg_norm.r(1000))\n",
    "    >> gr.tf_summarize(\n",
    "        pr_10=gr.mean(DF.x <= q_10), # Should be around 0.10\n",
    "        pr_50=gr.mean(DF.x <= q_50), # Should be around 0.50\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c658133",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Observations*\n",
    "\n",
    "- Are the `q_10` and `q_50` you computed above *sample* values or *true* values of `mg_norm`?\n",
    "  - (Your response here)\n",
    "- What does the line of code `pr_10=gr.mean(DF.x <= q_10)` compute?\n",
    "  - (Your response here)\n",
    "- Why are the values `pr_10` and `pr_50` not *exactly* equal to the probability values used to compute `q_10` and `q_50`?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c829e",
   "metadata": {},
   "source": [
    "## Conservative values\n",
    "\n",
    "Quantiles are a useful way to define *conservative* values associated with a desired probability. Rather than simply \"take the mean\" of a set of values, we can pick a small or larger probability and compute an associated quantile.\n",
    "\n",
    "For instance, since failure under tensile loading occurs when $\\sigma_{\\text{strength}} \\leq \\sigma_{\\text{applied}}$, taking a lower quantile of `tensile_strength` will provide a conservative value appropriate for design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8d75da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __q12__ Estimate a conservative strength\n",
    "\n",
    "Compute the empirical `0.10` quantile of the `tensile_strength` in `df_shewhart`; provide this as the column `lower`. Additionally, compute the sample mean of `tensile_strength`; provide this as the column `mean`. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d831a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Compute the lower 0.10 quantile and mean of `tensile_strength`\n",
    "df_values = (\n",
    "    df_shewhart \n",
    "    ## TODO: Compute `lower` and `mean`\n",
    "\n",
    ")\n",
    "\n",
    "# NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    \"lower\" in df_values.columns, \\\n",
    "    \"The result df_values does not have the column `lower`\"\n",
    "\n",
    "assert \\\n",
    "    \"mean\" in df_values.columns, \\\n",
    "    \"The result df_values does not have the column `mean`\"\n",
    "\n",
    "assert \\\n",
    "    df_values.lower.values[0] == gr.quant(df_shewhart.tensile_strength, 0.10), \\\n",
    "    \"incorrect value of `lower`\"\n",
    "\n",
    "print(df_values)\n",
    "print(\"\")\n",
    "print(\n",
    "    df_shewhart\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lower=gr.mean(DF.tensile_strength <= df_values.lower.values[0]),\n",
    "        pof_mean=gr.mean(DF.tensile_strength <= df_values['mean'].values[0]),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdff53a",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Are the `lower` and `mean` values that you computed *sample* values or *true* values?\n",
    "  - (Your response here)\n",
    "- What probability of failure `pof` is associated with the `lower` value? What probability of failure `pof` is associated with the `mean`?\n",
    "  - (Your response here)\n",
    "- Suppose the observed variability in the `tensile_strength` is real. Which of `mean` or `lower` is safer to use for design purposes? Why?\n",
    "  - (Your response here)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
