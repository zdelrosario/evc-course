{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d31bc67",
   "metadata": {},
   "source": [
    "# Stats: Confidence Intervals and the CLT\n",
    "\n",
    "*Purpose*: When studying a limited dataset, we need a principled way to report our results with their uncertainties. Confidence intervals (CI) are an excellent way to summarize results, and the central limit theorem (CLT) helps us to construct these intervals. Eventually, we will use the same ideas underlying CI's to detect patterns using *statistical process monitoring*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4b5a4",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddc18b6",
   "metadata": {},
   "source": [
    "# Theory Fundamentals\n",
    "\n",
    "To make sense of confidence intervals, we will need a bit of background information. First up: Why are we studying confidence intervals?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05560579",
   "metadata": {},
   "source": [
    "## Motivation: We might have seen other data\n",
    "\n",
    "Anytime we have a *particular* dataset, we should keep in mind that *we might have seen other data*.\n",
    "\n",
    "As a real example, let's take a real dataset and split it in two. The following code loads a datset of `tensile_strength` values and splits the full dataset into two smaller datasets. We could have seen either of these two datasets, had we gathered half as many values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_shewhart\n",
    "\n",
    "(\n",
    "    df_shewhart\n",
    "    >> gr.tf_mutate(dataset=DF.index % 2 + 1)\n",
    "    >> gr.ggplot(gr.aes(\"tensile_strength\"))\n",
    "    + gr.geom_freqpoly(gr.aes(linetype=\"factor(dataset)\"), bins=10)\n",
    "    + gr.scale_linetype_discrete(name=\"dataset\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bb996",
   "metadata": {},
   "source": [
    "We would draw different conclusions from these two different datasets. Dataset 1 has several observations with values over `~37,500` psi. However, Dataset 2 has no observations with values this large. In practice, we would have access to just one dataset; if we happened to have Dataset 2, we might assume that values of `tensile_strength` greater than `37,500` psi do not occur. Part of thinking statistically is keeping in mind possibilities like the one we see above: *we might have seen other data*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9477441",
   "metadata": {},
   "source": [
    "To underscore this idea of limited data, let's look at a simulated example. The following code defines a distribution with a specified mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "# Define an uncertain quantity\n",
    "mg_test = gr.marg_mom(\n",
    "    \"uniform\", \n",
    "    mean=0, \n",
    "    sd=1,\n",
    ")\n",
    "\n",
    "mg_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87441004",
   "metadata": {},
   "source": [
    "From the marginal summary, we can see that the mean of the distribution is `0`. However, if we have limited data then the mean of that sample will generally not be exactly zero:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f84391",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "# The true mean == 0; let's see what a limited sample gives\n",
    "gr.mean(mg_test.r(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2c7e4",
   "metadata": {},
   "source": [
    "Limited data leads to a form of error called *sampling error*. In practice we *almost always* have limited data, so sampling error is an unavoidable reality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d751f",
   "metadata": {},
   "source": [
    "## Sampling Distribution\n",
    "\n",
    "Let's imagine for a moment that we *did* carry out data collection multiple times. Let's illustrate this by splitting the tensile strength dataset into six separate subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a set of estimates\n",
    "(\n",
    "    df_shewhart\n",
    "    # Split into 6 groups\n",
    "    >> gr.tf_mutate(dataset=DF.specimen % 6 + 1)\n",
    "    # Compute the mean and variance over each sample\n",
    "    >> gr.tf_group_by(DF.dataset)\n",
    "    >> gr.tf_summarize(\n",
    "        tys_mu=gr.mean(DF.tensile_strength),\n",
    "        n=gr.n(DF.index),\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190fff27",
   "metadata": {},
   "source": [
    "Note that the mean `tys_mu` is *different* for each of the datasets. This is an example of *sampling error* (also called *sampling variability*). Statisticians quantify sampling error by defining a *population* from which a smaller dataset is drawn. This smaller dataset is called a *sample*. In the `tensile_strength` case, the population is the *infinite* number of parts that could be manufactured according to the same process. Any time we make a finite number of parts (any real batch of parts!), we have a limited sample from the manufacturing process.\n",
    "\n",
    "```{admonition} Sample vs Population\n",
    "A *population* is the full set of values we are interested in. A *sample* is a small subset from that population. Since the sample is not the population, it has less information than the full population. A mismatch between information in the population and information in the sample (e.g., the population mean vs sample mean) is called *sampling error*.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22d1d7",
   "metadata": {},
   "source": [
    "The *sampling distribution* is a conceptual tool used to quantify sampling variability in a chosen summary. Imagine that we repeatedly draw **random** samples (small datasets) of the same size from the target population. We then compute our chosen summary.\n",
    "\n",
    "The following code defines a population `mg_uniform`, draws samples of size `n=10`, and computes the sample mean. The true mean is `mean == 0`; the variability we see around this value is sampling variability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a uniform distribution\n",
    "# NOTE: The true mean is set here: `mean=0`\n",
    "mg_uniform = gr.marg_mom(\"uniform\", mean=0, sd=1)\n",
    "\n",
    "# Simulated example\n",
    "n = 10   # Sample size\n",
    "m = 1000 # Number of samples\n",
    "\n",
    "(\n",
    "    # Generate m=1000 samples of size n=10\n",
    "    gr.df_make(x=mg_uniform.r(n * m))\n",
    "    >> gr.tf_mutate(group=DF.index % m)\n",
    "    # Compute mean according to each sample\n",
    "    >> gr.tf_group_by(DF.group)\n",
    "    >> gr.tf_summarize(x_mean=gr.mean(DF.x))\n",
    "    >> gr.tf_ungroup()\n",
    "    # Visualize\n",
    "    >> gr.ggplot(gr.aes(\"x_mean\"))\n",
    "    + gr.geom_histogram(bins=30)\n",
    "    + gr.labs(\n",
    "        x=\"Sample Mean\",\n",
    "        y=\"Count\",\n",
    "        title=\"Histogram of the Sample Mean\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7812c17",
   "metadata": {},
   "source": [
    "Sampling distributions are not limited to the mean! The following code defines the same population `mg_uniform`, the same sample size `n=10`, but computes the probability that `X <= 0` rather than the mean. Note that the resulting sampling distribution looks quite different than the previous example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a uniform distribution\n",
    "# NOTE: The true mean is set here: `mean=0`\n",
    "mg_uniform = gr.marg_mom(\"uniform\", mean=0, sd=1)\n",
    "\n",
    "# Simulated example\n",
    "n = 10   # Sample size\n",
    "m = 1000 # Number of samples\n",
    "\n",
    "(\n",
    "    # Generate m=1000 samples of size n=10\n",
    "    gr.df_make(x=mg_uniform.r(n * m))\n",
    "    >> gr.tf_mutate(group=DF.index % m)\n",
    "    # Compute mean according to each sample\n",
    "    >> gr.tf_group_by(DF.group)\n",
    "    >> gr.tf_summarize(pr_lo=gr.pr(DF.x <= 0))\n",
    "    >> gr.tf_ungroup()\n",
    "    # Visualize\n",
    "    >> gr.ggplot(gr.aes(\"pr_lo\"))\n",
    "    + gr.geom_histogram(bins=15)\n",
    "    + gr.labs(\n",
    "        x=\"Sample Probability\",\n",
    "        y=\"Count\",\n",
    "        title=\"Histogram of the Sample Pr[X <= 0]\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a5a830",
   "metadata": {},
   "source": [
    "```{admonition} The Sampling Distribution is based on Population, Sample Size, and Summary\n",
    "The sampling distribution is a result of three ingredients: 1. The target population, 2. The chosen sample size, and 3. The chosen summary. The sampling distribution also assumes that each sample is drawn randomly from the population.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87440ad2",
   "metadata": {},
   "source": [
    "The sampling distribution is what we would observe under *repeated* data collection. However, gathering multiple datasets of the same size and computing independent summaries would be a highly inefficient way to use data! Instead, we can use the *central limit theorem* as a means to approximate a sampling distribution using *just one dataset*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2104f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Central Limit Theorem (CLT)\n",
    "\n",
    "The central limit theorem (CLT) is most easily stated in terms of the sample mean. Let $X \\sim \\rho$ be a random draw from a population with finite mean $\\mu$ and variance $\\sigma^2$. The sample mean is denoted $\\overline{X}_n$ and is defined as\n",
    "\n",
    "$$\\overline{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i.$$\n",
    "\n",
    "Under independent, repeated observations from the same distribution $X_i \\sim \\rho$, the central limit theorem states that $\\overline{X}_n$ becomes increasingly normal in its distribution as $n$ is increased, regardless of the original distribution $\\rho$. That is\n",
    "\n",
    "$$\\overline{X}_n \\stackrel{d}{\\to} N(\\mu, \\sigma^2/n),$$\n",
    "\n",
    "where $\\stackrel{d}{\\to}$ means \"convergence in distribution.\" The CLT is useful because it gives us a way to quantify sampling error: Since the CLT holds regardless of where the data came from $X \\sim \\rho$---so long as $|\\mu| < \\infty, \\sigma < \\infty$---then we can characterize the sampling error in the sample mean $\\overline{X}_n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4603ef8f",
   "metadata": {},
   "source": [
    "### __q1__ Study CLT convergence behavior\n",
    "\n",
    "Adjust the sample size `n` below, run the code to inspect the results each time, then answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Adjust the sample size n\n",
    "n = 1 # Sample size\n",
    "\n",
    "## NOTE: No need to edit\n",
    "# Draw a large sample\n",
    "df_sample = gr.df_make(x=mg_test.r(5000))\n",
    "\n",
    "(\n",
    "    # Compute mean within each group\n",
    "    df_sample\n",
    "    >> gr.tf_mutate(i=DF.index // n)\n",
    "    >> gr.tf_group_by(DF.i)\n",
    "    >> gr.tf_summarize(\n",
    "        x_mean=gr.mean(DF.x)\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    "    \n",
    "    # Visualize\n",
    "    >> gr.ggplot(gr.aes(\"x_mean\"))\n",
    "    + gr.geom_histogram(gr.aes(y=\"stat(density)\"), bins=30)\n",
    "    + gr.geom_line(\n",
    "        data=gr.df_make(x_mean=gr.linspace(-1.5, +1.5, 100))\n",
    "        >> gr.tf_mutate(\n",
    "            d=gr.marg_mom(\"norm\", mean=0, sd=1/gr.sqrt(n)).d(DF.x_mean)\n",
    "        ),\n",
    "        mapping=gr.aes(y=\"d\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8340f",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Around what value of $n$ does the histogram start to look like the normal distribution (black curve)?\n",
    "  - (Your response here)\n",
    "- How does the \"width\" of the histogram change with $n$?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10719b41",
   "metadata": {},
   "source": [
    "## Confidence Intervals (CI)\n",
    "\n",
    "Since any estimated quantity has sampling error, it is common to report estimated values along with a *confidence interval*. A confidence interval (CI) is an expression of *uncertainty*; it will tend to be wider when the sampling error is larger. For the moment, let's talk about how to *compute* a confidence interval; we'll discuss how to *interpret* a confidence interval in a bit.\n",
    "\n",
    "The CLT-based confidence interval for the mean is given by\n",
    "\n",
    "$$[\\overline{X}_n - z_C \\sigma/\\sqrt{n}, \\overline{X}_n + z_C \\sigma/\\sqrt{n}]$$\n",
    "\n",
    "where $z_C$ is the relevant quantile of a standard normal distribution. This is based on capturing a specified fraction $C$ of the distribution between the interval bounds. For instance, the following code computes $z_C$ for $C = 0.99$.\n",
    "\n",
    "```{admonition} Terminology: Point Estimate vs Confidence Interval\n",
    "A single value like a sample mean $\\overline{X}_n$ is called a *point estimate*, while a confidence interval is defined by two values (the interval endpoints).\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623f20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit, this computes the relevant z_C value\n",
    "C = 0.99 # 99% confidence level\n",
    "mg_standard = gr.marg_mom(\"norm\", mean=0, sd=1)\n",
    "z_C = mg_standard.q(1 - (1 - C)/2)\n",
    "print(\"z_C = {0:4.3f}\".format(z_C))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e6c9f2",
   "metadata": {},
   "source": [
    "You can compute these CI bounds manually. However, the helper functions `gr.mean_lo()` and `gr.mean_up()` automate these calculations. For both functions, you can adjust the confidence level `C` with the `alpha` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e700b6b9",
   "metadata": {},
   "source": [
    "### __q2__ Compute a confidence interval\n",
    "\n",
    "Use the helper functions `gr.mean_lo()` and `gr.mean_up()` to compute confidence limits for the mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Compute confidence limits for the mean;\n",
    "df_ci = (\n",
    "    gr.df_make(x=mg_test.r(10))\n",
    "    >> gr.tf_summarize(\n",
    "\n",
    "        # x_lo=???\n",
    "        x_mean=gr.mean(DF.x),\n",
    "\n",
    "        # x_up=???\n",
    "    )\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "assert \\\n",
    "    \"x_lo\" in df_ci.columns, \\\n",
    "    \"You must compute x_lo\"\n",
    "assert \\\n",
    "    \"x_up\" in df_ci.columns, \\\n",
    "    \"You must compute x_up\"\n",
    "assert \\\n",
    "    df_ci.x_lo[0] < df_ci.x_mean[0], \\\n",
    "    \"x_lo should be smaller than x_mean\"\n",
    "assert \\\n",
    "    df_ci.x_mean[0] < df_ci.x_up[0], \\\n",
    "    \"x_mean should be smaller than x_up\"\n",
    "\n",
    "df_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d94ce0e",
   "metadata": {},
   "source": [
    "### __q3__ Study the CI width\n",
    "\n",
    "The following code creates confidence intervals for samples of different sizes $n$. Run the following code, inspect the results, and answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe10a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_sweep = gr.df_grid()\n",
    "for i in [10, 20, 40, 80, 160]:\n",
    "    df_sweep = (\n",
    "        df_sweep\n",
    "        >> gr.tf_bind_rows(\n",
    "            gr.df_make(x=mg_test.r(i))\n",
    "            >> gr.tf_summarize(\n",
    "                x_lo=gr.mean_lo(DF.x),\n",
    "                x_up=gr.mean_up(DF.x),\n",
    "            )\n",
    "            >> gr.tf_mutate(\n",
    "                ci_width=DF.x_up - DF.x_lo,\n",
    "                n=i,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "(\n",
    "    df_sweep\n",
    "    >> gr.ggplot(gr.aes(\"n\", \"ci_width\"))\n",
    "    + gr.geom_line()\n",
    "    + gr.labs(\n",
    "        x=\"Sample Size n\",\n",
    "        y=\"CI Width\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03836c30",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Compare the CI width behavior (figure immediately above) with the definition given earlier. What explains the curve above?\n",
    "  - (Your response here)\n",
    "- To halve the CI width, how would you need to change the sample size?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a342f641",
   "metadata": {},
   "source": [
    "# Interpreting Confidence Intervals\n",
    "\n",
    "Confidence intervals are constructed in a way that seeks to *include* the true value that we seek to estimate. However, the nature of uncertainty means we need to exercise care when interpreting a confidence interval.\n",
    "\n",
    "## Golden Rule of Confidence Intervals\n",
    "\n",
    "```{admonition} The \"Golden Rule\" for interpreting Confidence Intervals\n",
    "When interpreting a confidence interval, we should assume the true value could be anywhere inside the interval.\n",
    "```\n",
    "\n",
    "Interpreting a CI as a range of possibilities helps us \"hedge our bets\". The point estimate may suggest a favorable conclusion, but if the CI is wide, then an unfavorable conclusion may also be possible.\n",
    "\n",
    "If a CI does not allow you to exclude an unfavorable possibility, it is an indication that you should gather another *larger* sample in order to study the same problem with greater statistical precision. You'll practice these ideas in the following exercises.\n",
    "\n",
    "```{admonition} Confidence in *procedure*, not in the interval\n",
    ":class: warning\n",
    "A subtle point about confidence intervals is that our confidence is in the long-run properties of constructing *many* intervals, not in any *single* interval. Any individual interval either does or does not include its true value: the \"probability\" for a single interval is either `0` or `1`.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43307253",
   "metadata": {},
   "source": [
    "### __q4__ Interpret these intervals\n",
    "\n",
    "Study the following intervals, answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba4d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "(\n",
    "    gr.df_make(\n",
    "        case=[\"A\", \"B\", \"C\", \"D\"],\n",
    "        x_lo=[ -1,   1,  -2,  -4],\n",
    "        x_mu=[  1, 1.5,  -1,  -3],\n",
    "        x_up=[  4,   2,   1,  -1],\n",
    "    )\n",
    "    >> gr.ggplot(gr.aes(\"case\"))\n",
    "    + gr.geom_errorbar(gr.aes(ymin=\"x_lo\", ymax=\"x_up\"))\n",
    "    + gr.geom_point(gr.aes(y=\"x_mu\"))\n",
    "    + gr.geom_hline(yintercept=0, linetype=\"dashed\")\n",
    "    + gr.coord_flip()\n",
    "    + gr.labs(\n",
    "        y=\"Value\",\n",
    "        x=\"Case\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4da3d0",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Is Case A greater than zero?\n",
    "  - (Your response here)\n",
    "- Is Case B greater than zero?\n",
    "  - (Your response here)\n",
    "- Is Case C less than zero?\n",
    "  - (Your response here)\n",
    "- Is Case D less than zero?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34f4bc",
   "metadata": {},
   "source": [
    "# Probability Estimation\n",
    "\n",
    "Remember that we learned in the previous exercise [stat04-distributions](https://zdelrosario.github.io/evc-course/exercises_solution/d19-e-stat04-distributions-solution.html#probability) that probability can be expressed as a mean (expectation). Thus, we can apply the same ideas about confidence intervals when estimating probabilities.\n",
    "\n",
    "To demonstrate, let's study a simple structural model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b5a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.models import make_cantilever_beam\n",
    "md_beam = make_cantilever_beam()\n",
    "md_beam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19abaef9",
   "metadata": {},
   "source": [
    "This model has two outputs that model failure modes: `g_stress <= 0` when the beam exceeds its maximum stress, and `g_disp <= 0` when the tip deflection is beyond its designed limit. We can assess the probability of failure for both failure modes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b84a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit\n",
    "(\n",
    "    md_beam\n",
    "    >> gr.ev_sample(n=100, df_det=\"nom\")\n",
    "    >> gr.tf_summarize(\n",
    "        pof_stress=gr.pr(DF.g_stress <= 0),\n",
    "        pof_disp=gr.pr(DF.g_disp <= 0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a276ec",
   "metadata": {},
   "source": [
    "Like the mean CI helpers, grama provides `gr.pr_lo()` and `gr.pr_up()` to easily compute confidence intervals on a probability:\n",
    "\n",
    "```{admonition} The probability CI helpers are different\n",
    "Note that the probability CI helpers `gr.pr_lo()` and `gr.pr_up()` are different from `gr.mean_lo()` and `gr.mean_up()`; namely, they only return values between `[0, 1]`. Make sure to only use the probability helpers when estimating probabilities!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdf0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "(\n",
    "    md_beam\n",
    "    >> gr.ev_sample(n=100, df_det=\"nom\", seed=101)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_stress <= 0),\n",
    "        pof=gr.pr(DF.g_stress <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_stress <= 0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e2135",
   "metadata": {},
   "source": [
    "This is an *extremely* wide confidence interval for the probability of failure; I get a value of `pof` anywhere between `0.003` and `0.11`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95855e60",
   "metadata": {},
   "source": [
    "### __q5__ Adjust the sample size\n",
    "\n",
    "Adjust the sample size `n` to achieve a CI width less than `0.1`.  Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7538b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Adjust the sample size\n",
    "df_pof = (\n",
    "    md_beam\n",
    "    >> gr.ev_sample(\n",
    "        # n=20, \n",
    "\n",
    "        df_det=\"nom\",\n",
    "    )\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_stress <= 0),\n",
    "        pof=gr.pr(DF.g_stress <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_stress <= 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use to check your work\n",
    "assert \\\n",
    "    abs(df_pof.pof_up[0] - df_pof.pof_lo[0]) < 0.1, \\\n",
    "    \"CI is too wide; increase `n`\"\n",
    "\n",
    "df_pof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5997b",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Is the `pof` smaller than `0.04`?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3546229",
   "metadata": {},
   "source": [
    "### __q6__ Design for small failure rate\n",
    "\n",
    "Adjust the deterministic variables `w` and `t` in order to *confidently* achieve a probability of failure due to stress less than `0.001`.\n",
    "\n",
    "*Hint*: You adjusted the sample size `n` in the previous exercise. Make sure to use that learning when tackling this exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00a8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Adjust the deterministic variables `w, t` to achieve a probability\n",
    "## of failure less than 0.001\n",
    "df_pof_small = (\n",
    "    md_beam\n",
    "    >> gr.ev_sample(\n",
    "        # n=20,\n",
    "        # df_det=gr.df_make(w=2.0, t=2.0),\n",
    "\n",
    "    )\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_stress <= 0),\n",
    "        pof=gr.pr(DF.g_stress <= 0),       # I find that pof ~= 0.0\n",
    "        pof_up=gr.pr_up(DF.g_stress <= 0), # pof_up must be < 0.001\n",
    "    )\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "print(df_pof_small)\n",
    "\n",
    "assert \\\n",
    "    df_pof_small.pof_up.values[0] < 0.001, \\\n",
    "    \"The upper CI bound for the POF is not less than 0.001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b988bc0",
   "metadata": {},
   "source": [
    "# Real vs Error\n",
    "\n",
    "In [stat02-source](https://zdelrosario.github.io/evc-course/exercises_solution/d08-e-stat02-source-solution.html#) we learned that we should treat real and erroneous sources of variability differently. Let's apply that thinking to the beam example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e47ee",
   "metadata": {},
   "source": [
    "### __q7__ Selecting the proper statistical technique\n",
    "\n",
    "Suppose the variability exhibited by the model `md_beam` is real. Study the results from the simulation below, and answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0215ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: No need to edit; run and inspect the results\n",
    "(\n",
    "    md_beam\n",
    "    >> gr.ev_sample(\n",
    "        n=1e4, \n",
    "        df_det=\"nom\",\n",
    "    )\n",
    "    >> gr.tf_summarize(\n",
    "        g_lo=gr.mean_lo(DF.g_stress),\n",
    "        g_mean=gr.mean(DF.g_stress),\n",
    "        g_up=gr.mean_up(DF.g_stress),\n",
    "\n",
    "        pof_lo=gr.pr_lo(DF.g_stress <= 0),\n",
    "        pof=gr.pr(DF.g_stress <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_stress <= 0),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e311f2",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Is the variability in `g_stress` real or erroneous?\n",
    "  - (Your response here)\n",
    "- Is the mean of `g_stress` greater than zero? How do you know?\n",
    "  - (Your response here)\n",
    "- What is the probability of failure due to stress?\n",
    "  - (Your response here)\n",
    "- Which of the two statistical techniques---computing the mean or computing a probability of failure---better characterizes the safety of this system? Why?\n",
    "  - (Your response here)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
