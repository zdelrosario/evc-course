{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8a3789",
   "metadata": {},
   "source": [
    "# Data: Separating and Uniting Columns\n",
    "\n",
    "*Purpose*: Data is easiest to use when it is *tidy*. In fact, grama is specifically designed to use tidy data. Last time we learned how to pivot data, but data can be untidy in other ways. Pivoting helped us when data were locked up in the *column headers*: This time, we'll learn how to use *separate* and *unite* to deal with *cell values* that are untidy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5bc3ae",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0337e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline\n",
    "\n",
    "# For assertion\n",
    "from pandas.api.types import is_integer_dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf2f95",
   "metadata": {},
   "source": [
    "# Separate and Unite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaadab4a",
   "metadata": {},
   "source": [
    "Sometimes data are presented in a *wide* format in order to fit many values on a page. You'll often see this form of data when looking at large datasets that have been prepared for a report (say, a UN population survey). For example, the following dataset is clearly not tidy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37a669",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "gr.df_make(\n",
    "    country=[\"Afghanistan\", \"Albania\", \"Algeria\"],\n",
    "    population_1995=[17586073, 3357858, 29315463],\n",
    "    population_1996=[18415307, 3341043, 29845208],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254d64c",
   "metadata": {},
   "source": [
    "The year of each population measurement is \"locked up\" in the column names. However, pivoting this dataset only gets us so far:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e59cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    gr.df_make(\n",
    "        country=[\"Afghanistan\", \"Albania\", \"Algeria\"],\n",
    "        population_1995=[17586073, 3357858, 29315463],\n",
    "        population_1996=[18415307, 3341043, 29845208],\n",
    "    )\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"population_1995\", \"population_1996\"],\n",
    "        names_to=\"name\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f623c",
   "metadata": {},
   "source": [
    "The column names are not simply cell values; they're a combination of both column names and cell values. To fully tidy this datset, we need to *separate* the names from the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307d1ec4",
   "metadata": {},
   "source": [
    "## The `gr.tf_separate()` verb\n",
    "\n",
    "The `gr.tf_separate()` verb allows us to separate *string-valued* columns on a target character. As a simple example, consider the following (silly) dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f89576",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    gr.df_make(s=[\"A-123\", \"B-456\", \"C-789\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089814e",
   "metadata": {},
   "source": [
    "If we wanted to separate the column `s` into two columns on the `-` character, we could do that with `gr.tf_separate()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5dd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    gr.df_make(s=[\"A-123\", \"B-456\", \"C-789\"])\n",
    "    >> gr.tf_separate(\n",
    "        column=\"s\",\n",
    "        sep=\"-\",\n",
    "        into=[\"letter\", \"numbers\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c52036",
   "metadata": {},
   "source": [
    "Note that we have two new columns with the separated values. We can use this approach to help tidy datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f796851b",
   "metadata": {},
   "source": [
    "### __q1__ Separate the `population` and `year`\n",
    "\n",
    "Use `gr.tf_separate()` to separate the `population` and `year` values into their own columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Separate the population and year columns\n",
    "df_pop = (\n",
    "    gr.df_make(\n",
    "        country=[\"Afghanistan\", \"Albania\", \"Algeria\"],\n",
    "        population_1995=[17586073, 3357858, 29315463],\n",
    "        population_1996=[18415307, 3341043, 29845208],\n",
    "    )\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"population_1995\", \"population_1996\"],\n",
    "        names_to=\"pop_year\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "print(df_pop)\n",
    "\n",
    "assert \\\n",
    "    \"population\" in df_pop.columns, \\\n",
    "    \"df_pop does not have a `population` column\"\n",
    "assert \\\n",
    "    \"year\" in df_pop.columns, \\\n",
    "    \"df_pop does not have a `year` column\"\n",
    "assert \\\n",
    "    df_pop.shape == (6, 4), \\\n",
    "    \"df_pop is the wrong shape\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b49bc6b",
   "metadata": {},
   "source": [
    "## The `gr.tf_unite()` verb\n",
    "\n",
    "The `gr.tf_unite()` verb performs the inverse of `gr.tf_separate()`; `gr.tf_unite()` allows us to combine multiple string columns into a single column. For example, we can undo the separation you performed above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300b5798",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "(\n",
    "    df_pop\n",
    "    >> gr.tf_unite(\n",
    "        \"population-year\",\n",
    "        DF.population,\n",
    "        DF.year,\n",
    "        sep=\"-\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff89698",
   "metadata": {},
   "source": [
    "Note that we have to choose what to name the new united column, the set of columns to combine, and a separator character with the `sep` argument. While the example above is not terribly practical, there are many cases where we'll have many strings that we might like to join.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10af17",
   "metadata": {},
   "source": [
    "### __q2__ Unite the digits\n",
    "\n",
    "Add the `area` code to the *front* of each `localnumber` to complete the following phone numbers. Provide the full number as the column `number`. Make sure to use the separator character `-`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60454ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK:\n",
    "df_numbers = (\n",
    "    gr.df_make(\n",
    "        localnumber=[\"255-2112\", \"255-4200\", \"867-5309\"],\n",
    "        area=[\"212\", \"650\", \"814\"],\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "print(df_numbers)\n",
    "\n",
    "assert \\\n",
    "    \"number\" in df_numbers.columns, \\\n",
    "    \"df_numbers does not have a `number` column\"\n",
    "assert \\\n",
    "    (df_numbers >> gr.tf_filter(gr.str_detect(DF.number, \"_\"))).shape[0] == 0, \\\n",
    "    \"Separator `_` detected; make sure to use `-` as your separator\"\n",
    "assert \\\n",
    "    (df_numbers >> gr.tf_filter(gr.str_detect(DF.number, \"^212|^650|^814\"))).shape[0] == 3, \\\n",
    "    \"The area codes are not at the *front* of the numbers\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732fafc3",
   "metadata": {},
   "source": [
    "# Case Study: Tidying an Alloy Dataset\n",
    "\n",
    "Now let's make use of `gr.tf_separate()` in tidying a more engineering-focused dataset. The following is a small dataset of measured aluminum alloy material properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6904951",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_alloys = gr.df_make(\n",
    "    thick=[0.022]*2 + [0.032]*2,\n",
    "    E_00=[10600, 10600, 10400, 10300],\n",
    "    mu_00=[0.321, 0.323, 0.329, 0.319],\n",
    "    E_45=[10700, 10500, 10400, 10500],\n",
    "    mu_45=[0.329, 0.331, 0.318, 0.326],\n",
    ")\n",
    "\n",
    "df_alloys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d154e0db",
   "metadata": {},
   "source": [
    "Note that this dataset is not tidy: The digits in the column names are the angles at which the alloys were tested. In order to tidy this dataset, we'll have to go through a few steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5dbc1c",
   "metadata": {},
   "source": [
    "### __q3__ Add a unique observation identifier\n",
    "\n",
    "Later, when we attempt a `gr.tf_pivot_wider()` down the line, we'll need a unique identifier for each row in the original dataset. Create a new column `id_obs` that uniquely identifies each row.\n",
    "\n",
    "*Hint*: You could just use the DataFrame's `index` column to do this....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79128931",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Add a unique identifier (UID) to each row\n",
    "df_alloys_id = (\n",
    "    df_alloys\n",
    "    ## TODO: Add a UID column, call it `id_obs`\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "print(df_alloys_id)\n",
    "\n",
    "assert \\\n",
    "    \"id_obs\" in df_alloys_id.columns, \\\n",
    "    \"df_alloys_id has no `id_obs` column\"\n",
    "\n",
    "assert \\\n",
    "    len(set(df_alloys_id.id_obs)) == len(df_alloys_id.id_obs), \\\n",
    "    \"The values in df_alloys_id.id_obs are not unique\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac5bfa3",
   "metadata": {},
   "source": [
    "### __q4__ Separate the `variable` and `angle` data\n",
    "\n",
    "The following code pivots the data longer; use `gr.tf_separate()` to separate the `variable` and `angle` data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Separate the `variable` and `angle` data\n",
    "df_alloys_separated = (\n",
    "    df_alloys_id\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"E_00\", \"E_45\", \"mu_00\", \"mu_45\"],\n",
    "        names_to=\"variable_angle\",\n",
    "        values_to=\"value\"\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: use this to check your work\n",
    "print(df_alloys_separated)\n",
    "\n",
    "assert \\\n",
    "    \"variable\" in df_alloys_separated.columns, \\\n",
    "    \"df_alloys_separated has no `variable` column\"\n",
    "\n",
    "assert \\\n",
    "    \"angle\" in df_alloys_separated.columns, \\\n",
    "    \"df_alloys_separated has no `angle` column\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f287886",
   "metadata": {},
   "source": [
    "### __q5__ Finish tidying the data\n",
    "\n",
    "Finish tidying the data: Use a pivot to move the `variable` names back to being column names, and make sure the `angle` values are integers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Finish tidying the data\n",
    "df_alloys_tidy = (\n",
    "    df_alloys_separated\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "print(df_alloys_tidy)\n",
    "\n",
    "assert \\\n",
    "    \"E\" in df_alloys_tidy.columns, \\\n",
    "    \"df_alloys_tidy does not have an `E` column\"\n",
    "assert \\\n",
    "    \"mu\" in df_alloys_tidy.columns, \\\n",
    "    \"df_alloys_tidy does not have an `mu` column\"\n",
    "assert \\\n",
    "    is_integer_dtype(df_alloys_tidy.angle), \\\n",
    "    \"df_alloys_tidy.angle is not an integer column\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b74bd",
   "metadata": {},
   "source": [
    "## Aside: What happens without the unique id?\n",
    "\n",
    "Above, I made a fuss about adding a unique id column to the dataset before we start pivoting. What happens if we don't do that?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90721acb",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# NOTE: Uncomment the code below and run this cell to see the error\n",
    "# (\n",
    "#     df_alloys\n",
    "#     # NOTE: I didn't add a UID here; let's see what happens....\n",
    "    \n",
    "#     >> gr.tf_pivot_longer(\n",
    "#         columns=[\"E_00\", \"E_45\", \"mu_00\", \"mu_45\"],\n",
    "#         names_to=\"varang\",\n",
    "#         values_to=\"value\"\n",
    "#     )\n",
    "#     >> gr.tf_separate(\n",
    "#         column=\"varang\",\n",
    "#         sep=\"_\",\n",
    "#         into=[\"var\", \"ang\"],\n",
    "#     )\n",
    "#     >> gr.tf_pivot_wider(\n",
    "#         names_from=\"var\",\n",
    "#         values_from=\"value\",\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbee9ed",
   "metadata": {},
   "source": [
    "We had to do a *lot* of work to tidy this dataset. Perhaps there's a better way?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b3952",
   "metadata": {},
   "source": [
    "## A *magic* option: `\".value\"`\n",
    "\n",
    "To help minimize some of the work necessary for tidying, `gr.tf_pivot_longer()` provides some special functionality. To illustrate this, let's take a look at a full tidying effort on a dataset similar to the alloy one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7ad8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit, this demonstrates the manual approach we've already seen\n",
    "(\n",
    "    gr.df_make(\n",
    "        A_01=[1,2,3,4],\n",
    "        A_02=[5,6,7,8],\n",
    "        B_01=[1,3,5,7],\n",
    "    )\n",
    "    # Generate a unique observation id\n",
    "    >> gr.tf_mutate(uid=DF.index)\n",
    "    # Pivot longer to turn column names into cell values\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"A_01\", \"A_02\", \"B_01\"],\n",
    "        names_to=\"varidx\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    "    # Separate the \"true\" column names from the cell entries\n",
    "    >> gr.tf_separate(\n",
    "        column=\"varidx\",\n",
    "        sep=\"_\",\n",
    "        into=[\"var\", \"idx\"],\n",
    "    )\n",
    "    # Pivot wider to place correct column names in header\n",
    "    >> gr.tf_pivot_wider(\n",
    "        names_from=\"var\",\n",
    "        values_from=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a441a23",
   "metadata": {},
   "source": [
    "This gets the job done. However, there is a much more succinct way to tidy this dataset using just one call to `gr.tf_pivot_longer()` with the `\".value\"` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e4f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit, this demonstrates the \".value\" approach\n",
    "(\n",
    "    gr.df_make(\n",
    "        A_01=[1,2,3,4],\n",
    "        A_02=[5,6,7,8],\n",
    "        B_01=[1,3,5,7],\n",
    "    )\n",
    "    \n",
    ">> gr.tf_pivot_longer(\n",
    "        columns=[\"A_01\", \"A_02\", \"B_01\"],\n",
    "        names_to=[\".value\", \"idx\"],\n",
    "        names_sep=\"_\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7d8e5b",
   "metadata": {},
   "source": [
    "This style of calling `gr.tf_pivot_longer()` with the `names_sep` argument effectively *embeds* a call to `gr.tf_separate()` within the pivot. The verb then automates the tedious steps of creating a unique ID and pivoting wider.\n",
    "\n",
    "In order to use this special functionality, we have to target the final column names using the special `\".value\"` argument. Note that this shows up in the `names_to` set of arguments; where we would have specified the name of the column that we would eventually pivot wider:\n",
    "\n",
    "```python\n",
    "    names_to=[\"var\", \"idx\"],\n",
    "    names_sep=\"_\",\n",
    "```\n",
    "\n",
    "we instead flag this column as the target to pivot wider with the special argument\n",
    "\n",
    "```python\n",
    "    names_to=[\".value\", \"idx\"],\n",
    "    names_sep=\"_\",\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154594cf",
   "metadata": {},
   "source": [
    "### __q6__ Use the `\".value\"` approach\n",
    "\n",
    "Use the `\".value\"` approach to tidy the alloy dataset in one pivot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28eefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Use the \".value\" approach to tidy the alloy dataset in one pivot\n",
    "(\n",
    "    gr.df_make(\n",
    "        thick=[0.022]*2 + [0.032]*2,\n",
    "        E_00=[10600, 10600, 10400, 10300],\n",
    "        mu_00=[0.321, 0.323, 0.329, 0.319],\n",
    "        E_45=[10700, 10500, 10400, 10500],\n",
    "        mu_45=[0.329, 0.331, 0.318, 0.326],\n",
    "    )\n",
    "\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
