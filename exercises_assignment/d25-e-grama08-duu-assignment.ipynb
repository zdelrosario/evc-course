{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43bb165",
   "metadata": {},
   "source": [
    "# Grama: Design Under Uncertainty\n",
    "\n",
    "*Purpose*: We don't model uncertainty just for fun: Once we have a model for uncertainty we can use it to do useful work, such as informing design decisions. In this exercise you will model a particular kind of uncertainty in built systems (variability in part geometry) and use your models to make design decisions that are resilient against the effects of uncertainty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917663c6",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30aeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "import pandas as pd\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc79a11",
   "metadata": {},
   "source": [
    "# Uncertainty in Engineering Systems\n",
    "\n",
    "The previous exercises `e-grama06-fit-univar` and `e-grama07-fit-multivar` covered the \"how\" and \"why\" of modeling uncertainties with distributions. In this exercise we'll study how uncertainty in the *inputs* of a model *propagates* to uncertainty in its outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1a319",
   "metadata": {},
   "source": [
    "## Perturbed Design Variables\n",
    "\n",
    "The realities of engineering manufacturing necessitate that built parts will be different from designed parts. In the previous exercise `e-grama07-fit-multivar` we saw a model for a circuit's performance. That system exhibited variability in its *realized component values*; we could pick the nominal (designed) component values `R, L, C`, but manufacturing variability would give rise to different as-made component values `Rr, Lr, Cr`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfb64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.models import make_prlc_rand\n",
    "md_circuit = make_prlc_rand()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98971df0",
   "metadata": {},
   "source": [
    "As a reminder, let's take a look at designed `C` and realized `Cr` values of the circuit capacitance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa42bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: No need to edit; run and inspect\n",
    "(\n",
    "    md_circuit\n",
    "    >> gr.ev_sample(n=1e3, df_det=\"nom\")\n",
    "    \n",
    "    >> gr.tf_summarize(\n",
    "        C=gr.mean(DF.C),\n",
    "        Cr_lo=gr.quant(DF.Cr, p=0.05),\n",
    "        Cr_mu=gr.mean(DF.Cr),\n",
    "        Cr_up=gr.quant(DF.Cr, p=0.95),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852ee6d",
   "metadata": {},
   "source": [
    "The results above indicate that the designed capicitance was around `50`, but values as low as `42.2` and as high as `87.8` occur too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4c6e1",
   "metadata": {},
   "source": [
    "### __q1__ Interpret the following density plot\n",
    "\n",
    "The nominal value for `Design 1` is `x = 0.5`, while the nominal value for `Design 2` is `x = 1.5`. However, parts manufactured according to both designs are subject to manufacturing variability, as depicted by the following densities. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf3a81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "mg_1 = gr.marg_mom(\"norm\", mean=+0.5, sd=0.1)\n",
    "mg_2 = gr.marg_mom(\"norm\", mean=+1.5, sd=0.1)\n",
    "\n",
    "(\n",
    "    gr.df_make(x=gr.linspace(0, +2, 100))\n",
    "    >> gr.tf_mutate(\n",
    "        y_1=mg_1.d(DF.x),\n",
    "        y_2=mg_2.d(DF.x),\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x\"))\n",
    "    + gr.annotate(\"segment\", x=+0.5, xend=+0.5, y=0, yend=4.25, linetype=\"dashed\")\n",
    "    + gr.annotate(\n",
    "        \"text\",\n",
    "        x=+0.5, y=4.5,\n",
    "        label=\"Design 1\",\n",
    "    )\n",
    "    + gr.annotate(\"segment\", x=+1.5, xend=+1.5, y=0, yend=4.25, linetype=\"dashed\")\n",
    "    + gr.annotate(\n",
    "        \"text\",\n",
    "        x=+1.5, y=4.5,\n",
    "        label=\"Design 2\",\n",
    "    )\n",
    "    + gr.geom_line(gr.aes(y=\"y_1\"), color=\"salmon\")\n",
    "    + gr.geom_line(gr.aes(y=\"y_2\"), color=\"cyan\")\n",
    "    \n",
    "    + gr.theme_minimal()\n",
    "    + gr.labs(\n",
    "        x=\"Realized Design Variable\",\n",
    "        y=\"Density\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb89b2c",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "For the following questions, assume that you can measure the Realized Design Variable `x` with *perfect* accuracy.\n",
    "\n",
    "- Suppose you have a part with `x == 0.61`. Which design specification was this most likely manufactured according to?\n",
    "  - (Your response here)\n",
    "- Suppose you selected a random part of `Design 2` off the manufacturing line and found that `x == 1.40`. Would you be surprised by this?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a5f6d",
   "metadata": {},
   "source": [
    "### __q2__ Set up a perturbation model\n",
    "\n",
    "Implement a model for a perturbed design variable $x_r$ following\n",
    "\n",
    "$$x_r = x + \\Delta x$$\n",
    "\n",
    "where $\\Delta x$ is normally distributed with mean $\\mu = 0$ and standard deviation $\\sigma = 0.1$.\n",
    "\n",
    "*Hint 1*: To do this, you'll need to add a function to the model that computes $x_r$, and a random variable for $\\Delta x$.\n",
    "\n",
    "*Hint 2*: The previous exercises `e-grama06-fit-univar` and `e-grama07-fit-multivar` cover how to model an uncertain quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68918900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TASK: Implement the model for x_r stated above\n",
    "\n",
    "md_dx = (\n",
    "    gr.Model(\"Perturbation\")\n",
    "    >> gr.cp_vec_function(\n",
    "        ## TODO: Implement a function for the perturbation\n",
    "\n",
    "        var=[\"x\", \"dx\"],\n",
    "        out=[\"x_r\"],\n",
    "    )\n",
    "    >> gr.cp_bounds(x=(-1, +1))\n",
    "    ## TODO: Use compositions to model the uncertainty of dx\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "gr.eval_sample(md_dx, n=1, df_det=\"nom\")\n",
    "    \n",
    "assert \\\n",
    "    'dx' in md_dx.density.marginals.keys(), \\\n",
    "    'No density for dx'\n",
    "assert \\\n",
    "    md_dx.density.marginals['dx'].d_param['loc'] == 0., \\\n",
    "    \"Density for dx has wrong mean\"\n",
    "assert \\\n",
    "    md_dx.density.marginals['dx'].d_param['scale'] == 0.1, \\\n",
    "    \"Density for dx has wrong standard deviation\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c70344",
   "metadata": {},
   "source": [
    "## Uncertainty Propagation\n",
    "\n",
    "Often, we model engineering outcomes *deterministically*; assuming certain inputs $x$ are known exactly, we produce a predictable output value $y$ based on a mathematical model $y = f(x)$.\n",
    "\n",
    "For example, we've previously looked at a model for the buckling strength of a rectangular plate\n",
    "\n",
    "$$\\sigma_{cr} = k_{cr} \\frac{\\pi^2 E}{12 (1 - \\mu^2)} \\left(\\frac{t}{b}\\right)^2.$$\n",
    "\n",
    "This is a *deterministic* model for the buckling strength $\\sigma_{cr}$ that depends on the plate geometry, such as the plate thickness $t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0f474",
   "metadata": {},
   "source": [
    "However, if the input values cannot be controlled exactly, it may be more appropriate to think of the model as having *perturbed* inputs $x_r = x + \\Delta x$. With perturbed inputs, the output is no longer precisely known, but is now subject to *uncertainty propagation*. We can think of this mathematically as \n",
    "\n",
    "$$y(x) = f(x_r) = f(x + \\Delta x).$$\n",
    "\n",
    "Where the input that the function \"sees\" is the perturbed input, rather than the deterministic input. This leads to uncertainty in the output $y$---the uncertainty *propagates* from the input to the output.\n",
    "\n",
    "Returning to the buckling strength example, if there were manufacturing variability in the plate thickness $t_r = t + \\Delta t$, then there would be uncertainty in the buckling strength\n",
    "\n",
    "$$\\sigma_{cr} = k_{cr} \\frac{\\pi^2 E}{12 (1 - \\mu^2)} \\left(\\frac{t + \\Delta t}{b}\\right)^2.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9511ac12",
   "metadata": {},
   "source": [
    "The following images depict uncertainty propagation schematically. First, let's look at a linear function $f(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d010fa1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# NOTE: No need to edit; this illustrates uncertainty propagation\n",
    "md_line = (\n",
    "    md_dx\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(y=0.5*df.x_r + 1),\n",
    "        var=[\"x_r\"],\n",
    "        out=[\"y\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "y_baseboard = 0.5\n",
    "\n",
    "(\n",
    "    md_line\n",
    "    >> gr.ev_sample(\n",
    "        n=5,\n",
    "        df_det=gr.df_make(x=(0.5, 1.5)),\n",
    "        seed=101,\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x_r\", \"y\"))\n",
    "    + gr.geom_hline(yintercept=y_baseboard, color=\"grey\", size=1)\n",
    "    + gr.geom_abline(intercept=1, slope=0.5, color=\"salmon\")\n",
    "    \n",
    "    + gr.geom_segment(gr.aes(xend=\"x_r\", yend=y_baseboard), linetype=\"dotted\")\n",
    "    + gr.geom_segment(gr.aes(xend=\"x\", y=y_baseboard, yend=y_baseboard), linetype=\"dotted\")\n",
    "    + gr.geom_segment(gr.aes(x=\"x\", xend=\"x\", y=0, yend=y_baseboard))\n",
    "    + gr.geom_point(size=1)\n",
    "    + gr.geom_point(gr.aes(y=y_baseboard), size=1)\n",
    "    + gr.geom_point(gr.aes(x=\"x\", y=0), size=1)\n",
    "    + gr.annotate(\n",
    "        \"text\",\n",
    "        x=0.9,\n",
    "        y=y_baseboard-0.1,\n",
    "        label=\"Realized x\",\n",
    "    )\n",
    "    \n",
    "    + gr.scale_x_continuous(limits=(0, 2))\n",
    "    + gr.theme_minimal()\n",
    "    + gr.labs(\n",
    "        x=\"Designed x\",\n",
    "        y=\"Resulting output y\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040f3f5",
   "metadata": {},
   "source": [
    "Here we have designed values of $x$ at $x = 0.5$ and $x = 1.5$. However, perturbations lead to variability in the realized values $x_r$, which in turn lead to variability in the output $y$.\n",
    "\n",
    "The variability in $y$ is roughly the same at both designed values $x$. However, a different function can lead to quite different results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600139b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# NOTE: No need to edit; this illustrates uncertainty propagation\n",
    "md_exp = (\n",
    "    md_dx\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(y=gr.exp(df.x_r)),\n",
    "        var=[\"x_r\"],\n",
    "        out=[\"y\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "y_baseboard = 0.5\n",
    "\n",
    "(\n",
    "    md_exp\n",
    "    >> gr.ev_sample(\n",
    "        n=5,\n",
    "        df_det=gr.df_make(x=(0.5, 1.5)),\n",
    "        seed=101,\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"x_r\", \"y\"))\n",
    "    + gr.geom_hline(yintercept=y_baseboard, color=\"grey\", size=1)\n",
    "    + gr.geom_line(\n",
    "        data=md_exp\n",
    "        >> gr.ev_nominal(df_det=gr.df_make(x=gr.linspace(0.2, 1.8, 100))),\n",
    "        mapping=gr.aes(\"x\"),\n",
    "        color=\"salmon\",\n",
    "    )\n",
    "    \n",
    "    + gr.geom_segment(gr.aes(xend=\"x_r\", yend=y_baseboard), linetype=\"dotted\")\n",
    "    + gr.geom_segment(gr.aes(xend=\"x\", y=y_baseboard, yend=y_baseboard), linetype=\"dotted\")\n",
    "    + gr.geom_segment(gr.aes(x=\"x\", xend=\"x\", y=0, yend=y_baseboard))\n",
    "    + gr.geom_point(size=1)\n",
    "    + gr.geom_point(gr.aes(y=y_baseboard), size=1)\n",
    "    + gr.geom_point(gr.aes(x=\"x\", y=0), size=1)\n",
    "    + gr.annotate(\n",
    "        \"text\",\n",
    "        x=0.96,\n",
    "        y=y_baseboard-0.2,\n",
    "        label=\"Realized x\",\n",
    "    )\n",
    "    \n",
    "    + gr.theme_minimal()\n",
    "    + gr.labs(\n",
    "        x=\"Designed x\",\n",
    "        y=\"Resulting output y\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456f1246",
   "metadata": {},
   "source": [
    "Once again we see variability in the realized values. However, note that the variability in the realized output `y` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927082c6",
   "metadata": {},
   "source": [
    "### __q3__ Do a sweep with propagated uncertainty\n",
    "\n",
    "Use your perturbation model `md_dx` to study how variability propagates through the function\n",
    "\n",
    "$$y(x) = f(x_r) = x_r^4.$$\n",
    "\n",
    "Sweep the design variable $x$ from at least $0.1$ to $1.0$, and make sure to use a sufficient number of observations in your random sample. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6eca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Evaluate a sweep with with propagated uncertainty\n",
    "df_dx = (\n",
    "    md_dx\n",
    "    # NOTE: No need to edit; this composes the output function\n",
    "    # with the perturbation model you implemented above\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(y=df.x_r**4),\n",
    "        var=[\"x_r\"],\n",
    "        out=[\"y\"],\n",
    "    )\n",
    "    \n",
    "    ## TODO: Evaluate a random sample\n",
    "\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "assert \\\n",
    "    isinstance(df_dx, pd.DataFrame), \\\n",
    "    \"df_dx is not a DataFrame; make sure to evaluate md_dx\"\n",
    "assert \\\n",
    "    df_dx.x.min() <= 0.1, \\\n",
    "    \"Make sure to sweep to a value as low as x == 0.1\"\n",
    "assert \\\n",
    "    df_dx.x.max() >= 1.0, \\\n",
    "    \"Make sure to sweep to a value as high as x == 1.0\"\n",
    "assert \\\n",
    "    len(set(df_dx.x)) >= 10, \\\n",
    "    \"Make sure to use a sufficient number of points in your sweep\"\n",
    "assert \\\n",
    "    len(set(df_dx.dx)) >= 100, \\\n",
    "    \"Make sure to use a sufficient number of points in your sample\"\n",
    "\n",
    "# Visualize\n",
    "(\n",
    "    df_dx\n",
    "    >> gr.ggplot(gr.aes(\"x\", \"y\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5891992d",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- What does the horizontal axis in the plot above represent: The designed value of `x` or the realized value of `x`?\n",
    "  - (Your response here)\n",
    "- Why is there variability in `y`?\n",
    "  - (Your response here)\n",
    "- Where (along the horizontal axis) is the variability in `y` large? Where is it small?\n",
    "  - (Your response here)\n",
    "- What about the underlying function `y = f(x)` explains the trends in variability you noted above?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b346fd",
   "metadata": {},
   "source": [
    "## Summarizing variability\n",
    "\n",
    "Visualizing variability with a scatterplot is a good first-step, but there are more effective ways to *summarize* variability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f3ae7",
   "metadata": {},
   "source": [
    "### __q4__ Summarize variability across a sweep\n",
    "\n",
    "Summarize the variability in $y$ at each value of $x$ by computing the mean `y_mu`, the 5% quantile `y_lo`, and the 95% quantile `y_up`. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a828eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dx_summary = (\n",
    "    df_dx\n",
    "    ## TODO: Summarize the result value `y` at each value of the\n",
    "    ## designed value `x`\n",
    "\n",
    "    ## NOTE: Clean up the grouping\n",
    "    >> gr.tf_ungroup()\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    set(df_dx.x) == set(df_dx_summary.x), \\\n",
    "    \"Incorrect grouping for df_dx_summary\"\n",
    "assert \\\n",
    "    \"y_lo\" in df_dx_summary.columns, \\\n",
    "    \"Make sure to compute a lower quantile y_lo\"\n",
    "assert \\\n",
    "    \"y_up\" in df_dx_summary.columns, \\\n",
    "    \"Make sure to compute an upper quantile y_up\"\n",
    "# Check the quantiles\n",
    "df_dx_check = (\n",
    "    df_dx\n",
    "    >> gr.tf_left_join(df_dx_summary, by=\"x\")\n",
    "    >> gr.tf_filter(DF.x == gr.min(DF.x))\n",
    "    >> gr.tf_summarize(\n",
    "        p_lo=gr.pr(DF.y <= DF.y_lo),\n",
    "        p_up=gr.pr(DF.y <= DF.y_up),\n",
    "    )\n",
    ")\n",
    "assert \\\n",
    "    abs(df_dx_check.p_lo[0] - 0.05) < 1e-3, \\\n",
    "    \"Lower quantile value is incorrect\"\n",
    "assert \\\n",
    "    abs(df_dx_check.p_up[0] - 0.95) < 1e-3, \\\n",
    "    \"Upper quantile value is incorrect\"\n",
    "\n",
    "(\n",
    "    df_dx_summary\n",
    "    >> gr.ggplot(gr.aes(\"x\"))\n",
    "    + gr.geom_ribbon(\n",
    "        mapping=gr.aes(ymin=\"y_lo\", ymax=\"y_up\"),\n",
    "        alpha=1/3,\n",
    "    )\n",
    "    + gr.geom_line(gr.aes(y=\"y_mu\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26af2ca",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "*Note*: This plot uses `geom_ribbon()`, which takes the aesthetics `ymin` and `ymax`. A ribbon is a useful way to visualize a region bounded by lower and upper values, such as quantiles!\n",
    "\n",
    "- Contrast this plot with the scatterplot from qX: What can you see in this ribbon plot that is harder to see in the scatterplot?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a10e5d8",
   "metadata": {},
   "source": [
    "# Designing for uncertainty\n",
    "\n",
    "We've seen that uncertainty can propagate through systems---what can we do about that? There are various ways we can design systems to mitigate the effects of uncertainty: We can seek *robust* designs, we can explicitly design for *reliability*, and we can *set tolerances* to achieve design targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4fe780",
   "metadata": {},
   "source": [
    "## Robustness\n",
    "\n",
    "Sometimes, the best nominal performance does not result in the overall \"best\" design. Since uncertainty can propagate, a design that is highly sensitive to input variability can fail to live up to the promise of its best nominal performance. The following example will guide you through thinking about designs that are *robust*, in the sense that they are resistant to uncertainty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; this sets up a model with\n",
    "## a perturbed input and a complex output function\n",
    "md_poly = (\n",
    "    gr.Model(\"Polynomial\")\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            x_r=df.x + df.dx\n",
    "        ),\n",
    "        var=[\"x\", \"dx\"],\n",
    "        out=[\"x_r\"],\n",
    "        name=\"Realized design\"\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            y=(df.x_r + 0.6) \n",
    "             *(df.x_r + 0.4) \n",
    "             *(df.x_r - 0.65)\n",
    "             *(df.x_r - 0.55)\n",
    "             *13.5 * (1 + gr.exp(8.0 * df.x_r))\n",
    "        ),\n",
    "        var=[\"x_r\"],\n",
    "        out=[\"y\"],\n",
    "        name=\"Realized output\"\n",
    "    )\n",
    "    >> gr.cp_bounds(x=(-1, +1))\n",
    "    >> gr.cp_marginals(dx=gr.marg_mom(\"norm\", mean=0, sd=0.03))\n",
    "    >> gr.cp_copula_independence()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02805430",
   "metadata": {},
   "source": [
    "### __q5__ Interpret this plot\n",
    "\n",
    "Run the following code and inspect the plot. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac790b1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; run and inspect\n",
    "# Evaluate model without uncertainty\n",
    "df_poly_nom = (\n",
    "    md_poly\n",
    "    >> gr.ev_nominal(\n",
    "        df_det=gr.df_make(x=gr.linspace(-1, +1, 100)),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Evaluate with uncertainty, take quantiles\n",
    "df_poly_mc = (\n",
    "    md_poly\n",
    "    >> gr.ev_sample(\n",
    "        df_det=gr.df_make(x=gr.linspace(-1, +1, 100)),\n",
    "        n=40,\n",
    "        seed=101,\n",
    "    )\n",
    "    >> gr.tf_group_by(\"x\")\n",
    "    >> gr.tf_summarize(\n",
    "        y_lo=gr.quant(DF.y, p=0.05),\n",
    "        y_mu=gr.median(DF.y),\n",
    "        y_up=gr.quant(DF.y, p=0.95),\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "(\n",
    "    df_poly_mc\n",
    "    >> gr.tf_mutate(source=\"Quantiles\")\n",
    "    >> gr.ggplot(gr.aes(\"x\"))\n",
    "    + gr.geom_line(\n",
    "        data=df_poly_nom\n",
    "        >> gr.tf_mutate(source=\"Nominal\"),\n",
    "        mapping=gr.aes(y=\"y\"),\n",
    "    )\n",
    "    + gr.geom_ribbon(\n",
    "        mapping=gr.aes(ymin=\"y_lo\", ymax=\"y_up\"),\n",
    "        alpha=1/3,\n",
    "    )\n",
    "    \n",
    "    + gr.scale_y_continuous(breaks=(-10, -5, 0, +5, +10, +15, +20))\n",
    "    + gr.coord_cartesian(ylim=(-10, 20))\n",
    "    + gr.theme_minimal()\n",
    "    + gr.guides(color=None)\n",
    "    + gr.labs(\n",
    "        x=\"Designed input value x\",\n",
    "        y=\"Realized output value y\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ca4773",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "For this example, *lower* values of `y` are better. The solid curve depicts the `Nominal` output value, while the shaded region visualizes the 5% to 95% quantiles.\n",
    "\n",
    "- *Approximately*, what is the lowest value `y` value the `Nominal` curve (solid curve) achieves across the values of `x` depicted above?\n",
    "  - (Your response here)\n",
    "- *Approimately*, what is the value of `y` for the `Nominal` curve at `x = -0.5`?\n",
    "  - (Your response here)\n",
    "- Note the spread between the `Quantiles` at $x \\approx 0.6$. *Approximately* what range of `y` values would you expect to result from releated manufacturing at $x \\approx 0.6$?\n",
    "  - (Your response here)\n",
    "- Note the spread between the `Quantiles` at $x \\approx -0.5$. *Approximately* what range of `y` values would you expect to result from releated manufacturing at $x \\approx -0.5$?\n",
    "  - (Your response here)\n",
    "- Suppose you plan to manufacture many parts according to this process, test all specimens, and choose the 5%. Which design (value of `x`) would you pick, and why?\n",
    "  - (Your response here)\n",
    "- Suppose you plan to manufacture many parts according to this process, all of which must work at an acceptable level. Which design (value of `x`) would you pick, and why?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9d596",
   "metadata": {},
   "source": [
    "## Reliability\n",
    "\n",
    "While *robustness* is about reducing variability, *reliability* is about avoiding unwanted failures. A *reliable* design is a design that has a low probability of failure. With a model for a system and its uncertainties, we can use uncertainty propagation to quantify the probability of failure, and use the model to test the reliability of different designs.\n",
    "\n",
    "For the remainder of this exercise, let's use the cantilever beam model as an example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20109bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.models import make_cantilever_beam\n",
    "md_beam = make_cantilever_beam()\n",
    "md_beam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b2d00",
   "metadata": {},
   "source": [
    "### __q6__ Compare the reliability of designs\n",
    "\n",
    "Estimate the probability of failure due to `stress` for the following cantilever beam designs. Make sure to compute lower and upper confidence interval bounds for your estimate, and choose a large enough sample size so that the CI for the designs do not overlap. Answer the questions under *observations* below.\n",
    "\n",
    "*Hint*: Remember that we learned about estimating probabilities of failure (and related confidence intervals) in `e-stat05-CI`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc34aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Estimate the reliability for the following beam designs\n",
    "\n",
    "# NOTE: No need to edit; evaluate these designs\n",
    "df_beam_designs = gr.df_make(\n",
    "    design=[\"Wide\", \"Tall\", \"Square\"],\n",
    "    w=[4, 2, gr.sqrt(8)],\n",
    "    t=[2, 4, gr.sqrt(8)],\n",
    ")\n",
    "\n",
    "## TASK: Complete the following code\n",
    "df_beam_results = (\n",
    "    md_beam\n",
    "    ## TODO: Approximate the POF due to stress for each design.\n",
    "    ## Make sure to provide a confidence interval as the columns [pof_lo, pof_up]\n",
    "\n",
    ")\n",
    "\n",
    "print(df_beam_results)\n",
    "\n",
    "## NOTE: No need to edit below; use this to check your work\n",
    "assert \\\n",
    "    isinstance(df_beam_results, pd.DataFrame), \\\n",
    "    \"df_beam_results is not a DataFrame; make sure to evaluate and summarize\"\n",
    "assert \\\n",
    "    {\"Square\", \"Tall\", \"Wide\"} == set(df_beam_results.design), \\\n",
    "    \"df_beam_results does not contain rows for each design; make sure to group appropriately\"\n",
    "assert \\\n",
    "    \"pof_lo\" in df_beam_results.columns, \\\n",
    "    \"CI lower bound pof_lo not found in df_beam_results; make sure to compute a lower CI bound\"\n",
    "assert \\\n",
    "    \"pof_up\" in df_beam_results.columns, \\\n",
    "    \"CI upper bound pof_up not found in df_beam_results; make sure to compute an upper CI bound\"\n",
    "assert \\\n",
    "    df_beam_results[df_beam_results.design==\"Tall\"].pof_up.values[0] < \\\n",
    "    df_beam_results[df_beam_results.design==\"Square\"].pof_lo.values[0], \\\n",
    "    \"CI overlap; make sure to use a sufficiently large sample size\"\n",
    "assert \\\n",
    "    df_beam_results[df_beam_results.design==\"Square\"].pof_up.values[0] < \\\n",
    "    df_beam_results[df_beam_results.design==\"Wide\"].pof_lo.values[0], \\\n",
    "    \"CI overlap; make sure to use a sufficiently large sample size\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c0533",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "- Which design has the lowest probability of failure?\n",
    "  - (Your response here)\n",
    "- All of these designs have the same cross-sectional area; they vary from wide to square to tall in their rectangular cross-section shape. Based on the result above, does width or tallness of the cross-section seem to be more important for safe operation?\n",
    "  - (Your response here)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b0fbf",
   "metadata": {},
   "source": [
    "## Setting Tolerances\n",
    "\n",
    "Once we represent uncertainty in a model, we can make modifications to that model to make quantitative statements about system performance. For instance, modeling the tolerances for a manufactured component will allow us to test different tolerance scenarios. This can help us decide whether to ask manufacturing to tighten specific tolerances.\n",
    "\n",
    "The following code adds a perturbation model for tolerances on the width and tallness of the cantilever beam. You'll use this model below to test different tolerance scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fcdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: NO need to edit; this adds tolerances to the cantilever beam model\n",
    "md_beam_tolerances = (\n",
    "    gr.Model()\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            w=df.w0 + df.dw,\n",
    "            t=df.t0 + df.dt,\n",
    "        ),\n",
    "        var=[\"w0\", \"t0\", \"dw\", \"dt\"],\n",
    "        out=[\"w\", \"t\"],\n",
    "        name=\"Design perturbations\",\n",
    "    )\n",
    "    ## NOTE: gr.cp_md_det() is an advanced tool I'm using to\n",
    "    ## avoid re-defining the entire beam model. You could\n",
    "    ## accomplish the same thing with gr.cp_vec_function()\n",
    "    ## and the beam equations\n",
    "    >> gr.cp_md_det(md_beam)\n",
    "    ## Define the input space\n",
    "    >> gr.cp_bounds(\n",
    "        w0=(2, 4),\n",
    "        t0=(2, 4),\n",
    "    )\n",
    "    >> gr.cp_marginals(\n",
    "        # Uncertainties from the original model\n",
    "        H=gr.marg_mom(\"norm\", mean=500, sd=100),\n",
    "        V=gr.marg_mom(\"norm\", mean=1000, sd=100),\n",
    "        E=gr.marg_mom(\"norm\", mean=2.9e7, sd=1.45e6),\n",
    "        Y=gr.marg_mom(\"norm\", mean=40000, sd=2000),\n",
    "        # Variability in width and tallness\n",
    "        dw=gr.marg_mom(\"uniform\", mean=0, sd=1e-1),\n",
    "        dt=gr.marg_mom(\"uniform\", mean=0, sd=1e-1),\n",
    "    )\n",
    "    >> gr.cp_copula_independence()\n",
    ")\n",
    "md_beam_tolerances \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a535003",
   "metadata": {},
   "source": [
    "First, let's evaluate the baseline tolerance model to assess the probability of failure for a few designs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b82da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; this estimates probabilities of failure\n",
    "## for the three designs\n",
    "df_beam_baseline = (\n",
    "    md_beam_tolerances\n",
    "    >> gr.ev_sample(\n",
    "        n=1e4, \n",
    "        df_det=gr.df_make(\n",
    "            design=[\"Wide\", \"Tall\", \"Square\"],\n",
    "            w0=[4, 2, gr.sqrt(8)],\n",
    "            t0=[2, 4, gr.sqrt(8)],\n",
    "        ), \n",
    "        seed=101,\n",
    "    )\n",
    "    >> gr.tf_group_by(DF.design)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_stress <= 0),\n",
    "        pof_mu=gr.pr(DF.g_stress <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_stress <= 0),\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    "    >> gr.tf_mutate(model=\"Baseline\")\n",
    ")\n",
    "df_beam_baseline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24556325",
   "metadata": {},
   "source": [
    "### __q7__ Recommend reasonable tolerances\n",
    "\n",
    "Adjust the manufacturing tolerances to find desirable manufacturing targets. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Tweak the tolerances\n",
    "\n",
    "df_beam_tweaked = (\n",
    "    md_beam_tolerances\n",
    "    >> gr.cp_marginals(\n",
    "        ## TODO: Override the marginals for dw and dt to test different \n",
    "        ## manufacturing tolerances\n",
    "\n",
    "    )\n",
    "    ## NOTE: No need to edit below; this analyzes your model\n",
    "    >> gr.ev_sample(\n",
    "        n=1e4, \n",
    "        df_det=gr.df_make(\n",
    "            design=[\"Wide\", \"Tall\", \"Square\"],\n",
    "            w0=[4, 2, gr.sqrt(8)],\n",
    "            t0=[2, 4, gr.sqrt(8)],\n",
    "        ), \n",
    "        seed=101,\n",
    "    )\n",
    "    >> gr.tf_group_by(DF.design)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_stress <= 0),\n",
    "        pof_mu=gr.pr(DF.g_stress <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_stress <= 0),\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    "    >> gr.tf_mutate(model=\"Tweaked\")\n",
    ")\n",
    "\n",
    "## NOTE: This will visualize your results with\n",
    "## a comparison against the baseline model\n",
    "(\n",
    "    df_beam_baseline\n",
    "    >> gr.tf_bind_rows(df_beam_tweaked)\n",
    "    >> gr.ggplot(gr.aes(\"design\", color=\"model\"))\n",
    "    + gr.geom_errorbar(\n",
    "        gr.aes(ymin=\"pof_lo\", ymax=\"pof_up\"),\n",
    "        position=gr.position_dodge(width=0.5),\n",
    "    )\n",
    "    + gr.geom_point(\n",
    "        gr.aes(y=\"pof_mu\"), \n",
    "        position=gr.position_dodge(width=0.5),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cbaf12",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "*Note*: It's likely you'll need to tweak and re-run the analysis above to answer these questions:\n",
    "\n",
    "- Suppose you could reduce the standard deviation `sd` to `1e-3` for both the width `dw` and tallness `dt` tolerances. Which designs would this benefit?\n",
    "  - (Your response here)\n",
    "- Consider the `Tall` design. Suppose it were only economical to reduce **one** of the tolerances: either for `dw` or `dt`. Which would be the more valuable tolerance to reduce?\n",
    "  - (Your response here)\n",
    "- In *q6 Compare the reliability of designs*, you answered the question \"does the *nominal* width or tallness of the cross-section seem to be more important for safe operation?\" How does your answer immediately above compare with your past answer?\n",
    "  - (Your response here)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
