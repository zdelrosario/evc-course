{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "western-institution",
   "metadata": {},
   "source": [
    "# c05-plates\n",
    "\n",
    "*Purpose*: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-peninsula",
   "metadata": {},
   "source": [
    "## Informed Consent\n",
    "\n",
    "As a reminder, this course is part of a study of engineers' behavior. While not all parts of the course include data collection, we will analyze your responses to this homework as part of the research.\n",
    "\n",
    "We will analyze your answers to this homework, and may quote this work as part of published research.\n",
    "\n",
    "You can ask to have your responses excluded from the study after the interview by sending us an email. Before starting this assignment, do you consent to sharing your work with the study?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-redhead",
   "metadata": {},
   "source": [
    "I agree to share my responses with the study\n",
    "\n",
    "- (Please type your name here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grama as gr\n",
    "import pandas as pd\n",
    "DF = gr.Intention()\n",
    "%matplotlib inline\n",
    "\n",
    "# For assertion\n",
    "from pandas.api.types import is_numeric_dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-terror",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "(This continues the stang challenge.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-terrorist",
   "metadata": {},
   "source": [
    "# Assess Statistical Control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-console",
   "metadata": {},
   "source": [
    "### __qX__ Assess statistical control of `E` across thicknesses\n",
    "\n",
    "Construct a control chart with groupings according to plate thickness. Assess the state of statistical control of the elasticity. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Construct a control chart\n",
    "(\n",
    "    df_stang\n",
    "# solution-begin\n",
    "    >> gr.pt_xbs(group=\"thick\", var=\"E\")\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-singles",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Is the variability of `E` under statistical control across plate thicknesses? How do you know?\n",
    "  - (Your response here)\n",
    "- Is the mean of `E` under statistical control across plate thicknesses? How do you know?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Is the variability of `E` under statistical control? How do you know?\n",
    "  - Likely yes; the points are all within the control limits and there are no patterns in the data.\n",
    "- Is the mean of `E` under statistical control? How do you know?\n",
    "  - No; there are several violations of the control limits. In particular, the thickest plates have a much lower elasticity than the other specimens.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-demand",
   "metadata": {},
   "source": [
    "## Follow-up experiment\n",
    "\n",
    "*Note*: The following data were simulated; they do not correspond to physical experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"./data/c05-data.csv\")\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-vintage",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Symbol | Variable | Meaning |\n",
    "|---|---|---|\n",
    "| `E` | Elasticity (ksi) | Mechanical property |\n",
    "| `mu` | Poisson's ratio (-) | Mechanical property |\n",
    "| `t` | Thickness (in) | Geometric property |\n",
    "| `id_machine` | Unique machine identifier | Manufacturing variable |\n",
    "| `id_specimen` | Unique specimen identifier | Manufacturing variable |\n",
    "| `id_measurement` | Unique measurement (operator) identifier | Manufacturing variable |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-touch",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __qX__ Explore the experimental design\n",
    "\n",
    "Answer the following questions to better understand the experimental design. Note that the same questions are posed within each cell and under *observations* below.\n",
    "\n",
    "*Hint*: The verbs `tf_count()` and `tf_distinct()` will be very useful for answering some of these questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: What thicknesses were tested?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_count(DF.t)\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: How many unique specimens were manufactured?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_summarize(spec_max=gr.max(DF.id_specimen) + 1)\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: How many specimens were made on each machine?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_distinct(DF.id_specimen, DF.id_machine)\n",
    "    >> gr.tf_count(DF.id_machine)\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q: How many times did each operator measure each specimen?\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_count(DF.id_specimen, DF.id_measurement)\n",
    "    >> gr.tf_summarize(n_max=gr.max(DF.n))\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-carnival",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- What thicknesses were tested?\n",
    "  - (Your response here)\n",
    "- How many unique specimens were manufactured?\n",
    "  - (Your response here)\n",
    "- How many specimens were made on each machine?\n",
    "  - (Your response here)\n",
    "- How many times did each operator measure each specimen?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- What thicknesses were tested?\n",
    "  - 0.125 and 0.250 inches\n",
    "- How many unique specimens were manufactured?\n",
    "  - 120\n",
    "- How many specimens were made on each machine?\n",
    "  - 20 specimens each\n",
    "- How many times did each operator measure each specimen?\n",
    "  - Just once\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disturbed-style",
   "metadata": {},
   "source": [
    "### __qX__ Compare across thicknesses\n",
    "\n",
    "Compare the elasticity across plate thicknesses; does elasticity seem to be consistent across thickness?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Compare elasticity across thicknesses\n",
    "## NOTE: There are many ways to do this!\n",
    "(\n",
    "    df_data\n",
    "# solution-begin\n",
    "    >> gr.ggplot(gr.aes(\"t\", \"E\"))\n",
    "    + gr.geom_boxplot(gr.aes(group=\"t\"), notch=True)\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-universal",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Is thickness consistent across plate thickness?\n",
    "  - (Your response here)\n",
    "- Will it be reasonable to group together plates of different thicknesses when assessing statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Is thickness consistent across plate thickness?\n",
    "  - No; from the plot above, we can see a significant difference in median plate elasticity across thickness.\n",
    "- Will it be reasonable to group together plates of different thicknesses when assessing statistical control? Why or why not?\n",
    "  - No; when assessing statistical control we should use groups within which the behavior is consistent. Since we have identified a strong inconsistency across thickness, each thickness should be treated separately.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-cookbook",
   "metadata": {},
   "source": [
    "### __qX__ Assess statistical control of Poisson's ratio\n",
    "\n",
    "Consider only the `t == 0.250` plates. Assess the state of statistical control of Poisson's ratio. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assess the state of statistical control\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF.t == 0.250)\n",
    "    >> gr.pt_xbs(group=\"id_measurement\", var=\"mu\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-feature",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Is `mu` under statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Is `mu` under statistical control? Why or why not?\n",
    "  - Likely yes; there are no patterns in the variability or mean of `mu`.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-cameroon",
   "metadata": {},
   "source": [
    "### __qX__ Assess statistical control of elasticity\n",
    "\n",
    "Consider only the `t == 0.250` plates. Assess the state of statistical control of the elasticity. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Assess the state of statistical control\n",
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF.t == 0.250)\n",
    "    >> gr.pt_xbs(group=\"id_measurement\", var=\"E\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(DF.t == 0.250)\n",
    "    >> gr.pt_xbs(group=\"id_machine\", var=\"E\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-librarian",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- Why is it important that we limit this analysis to `t == 0.25` plates?\n",
    "  - (Your response here)\n",
    "- Is `E` under statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "- Based on the group variable(s) you chose, what follow-up investigations should be done?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- Why is it important that we limit this analysis to `t == 0.25` plates?\n",
    "  - We saw above that the thinnest `t == 0.125` and thickest `t == 0.25` plates have significantly different mean elasticities. Therefore, it is not valid to lump thin and thick plates in the same group. Limiting to `t == 0.25` plates is one way to avoid this erroneous grouping.\n",
    "- Is `E` under statistical control? Why or why not?\n",
    "  - No; the mean elasticity violates the control limits for Machines C and D, and the variability of elasticity violates the UCL for measurement h.\n",
    "- Based on the group variable(s) you chose, what follow-up investigations should be done?\n",
    "  - We should investigate Machines C and D, and operator h.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-serbia",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __qX__ Assess statistical control of elasticity (Pt. 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(\n",
    "        DF.t == 0.250,\n",
    "        DF.id_machine != \"C\",\n",
    "        DF.id_measurement != \"h\",\n",
    "    )\n",
    "# solution-begin\n",
    "    >> gr.pt_xbs(group=\"id_machine\", var=\"E\")\n",
    "# solution-end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution-begin\n",
    "(\n",
    "    df_data\n",
    "    >> gr.tf_filter(\n",
    "        DF.t == 0.250,\n",
    "        DF.id_machine != \"C\",\n",
    "        DF.id_measurement != \"h\",\n",
    "    )\n",
    "    \n",
    "    >> gr.pt_xbs(group=\"id_measurement\", var=\"E\")\n",
    ")\n",
    "# solution-end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-norwegian",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- For the set of machines and operators considered, is `E` under statistical control? Why or why not?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- For the set of machines and operators considered, is `E` under statistical control? Why or why not?\n",
    "  - Likely yes; we see no patterns across machines or operators.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-samuel",
   "metadata": {},
   "source": [
    "# Consider Sources of Variability\n",
    "\n",
    "(TODO)\n",
    "\n",
    "For the rest of the exercise, we will consider the following subset of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit\n",
    "df_sub = (\n",
    "    df_data\n",
    "    >> gr.tf_filter(\n",
    "        DF.t == 0.250,\n",
    "        DF.id_machine != \"C\",\n",
    "        DF.id_measurement != \"h\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-relations",
   "metadata": {},
   "source": [
    "### __qX__ Estimate the real variability\n",
    "\n",
    "Identify the column in `df_sub` that groups together multiple measurements of the same quantity.\n",
    "\n",
    "The code below applies the *mean heuristic* ([e-stat02-source](https://zdelrosario.github.io/evc-course/exercises_solution/d08-e-stat02-source-solution.html#heuristics)) to produce a more stable measurement, then compute the variance across these more stable measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK: Apply the Mean Heuristic to group by the appropriate variable\n",
    "df_var_mfg = (\n",
    "    df_sub\n",
    "# task-begin\n",
    "    ## TODO: Group by the appropriate variable\n",
    "# task-end\n",
    "# solution-begin\n",
    "    >> gr.tf_group_by(DF.id_specimen)\n",
    "# solution-end\n",
    "    >> gr.tf_summarize(E=gr.mean(DF.E))\n",
    "    >> gr.tf_ungroup()\n",
    "    >> gr.tf_summarize(E_var_mfg=gr.var(DF.E))\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    abs(df_var_mfg.E_var_mfg[0] - 109670.635716) < 1e-6, \\\n",
    "    \"Incorrect variance; make sure you grouped by the correct variable\"\n",
    "\n",
    "df_var_mfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-diamond",
   "metadata": {},
   "source": [
    "### __qX__ Estimate the measurement variability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var_meas = (\n",
    "    df_sub\n",
    "# solution-begin\n",
    "    >> gr.tf_group_by(DF.id_specimen)\n",
    "    >> gr.tf_summarize(E_var=gr.var(DF.E))\n",
    "    >> gr.tf_ungroup()\n",
    "    >> gr.tf_summarize(E_var_meas=gr.mean(DF.E_var))\n",
    "# solution-end\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit; use this to check your work\n",
    "assert \\\n",
    "    abs(df_var_meas.iloc[0, 0] - 168382.91387) < 1e-6, \\\n",
    "    \"Incorrect variance; make sure you grouped by the correct variable\"\n",
    "\n",
    "df_var_meas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-mathematics",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = (\n",
    "    df_sub\n",
    "    >> gr.tf_group_by(DF.id_specimen)\n",
    "    >> gr.tf_summarize(\n",
    "        mu=gr.mean(DF.mu),\n",
    "        E=gr.mean(DF.E),\n",
    "    )\n",
    "    >> gr.tf_ungroup()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-implement",
   "metadata": {},
   "source": [
    "# Model Variability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-database",
   "metadata": {},
   "source": [
    "### __qX__ Assess dependency of `E` and `mu`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_sub\n",
    "    >> gr.ggplot(gr.aes(\"E\", \"mu\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-hygiene",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_plate = (\n",
    "    gr.Model(\"Plate critical buckling stress\")\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            k_cr=(df.m * df.b / df.a + df.a / df.m / df.b)**2\n",
    "        ),\n",
    "        var=[\"a\", \"b\", \"m\"],\n",
    "        out=[\"k_cr\"],\n",
    "        name=\"Shape factor\",\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            sigma_cr=df.k_cr * (3.14**3/12) * df.E*1e3 / (1 - df.mu**2)\n",
    "                    *(df.t / df.b)**2\n",
    "        ),\n",
    "        var=[\"k_cr\", \"E\", \"mu\", \"t\", \"b\"],\n",
    "        out=[\"sigma_cr\"],\n",
    "        name=\"Buckling stress\",\n",
    "    )\n",
    "    >> gr.cp_vec_function(\n",
    "        fun=lambda df: gr.df_make(\n",
    "            g_buckle=df.sigma_cr - 2e5 / df.b / df.t,\n",
    "        ),\n",
    "        var=[\"sigma_cr\", \"b\", \"t\"],\n",
    "        out=[\"g_buckle\"],\n",
    "        name=\"Limit state: Buckling\",\n",
    "    )\n",
    ")\n",
    "\n",
    "md_plate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-sweden",
   "metadata": {},
   "source": [
    "### __qX__ Fit with all observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_total = (\n",
    "    md_plate\n",
    "# solution-begin\n",
    "    >> gr.cp_marginals(\n",
    "        E=gr.marg_fit(\"lognorm\", df_sub.E, floc=0),\n",
    "        mu=gr.marg_fit(\"lognorm\", df_sub.mu, floc=0),\n",
    "    )\n",
    "    >> gr.cp_copula_independence()\n",
    "# solution-end\n",
    ")\n",
    "md_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-table",
   "metadata": {},
   "source": [
    "### __qX__ Fit with averaged observations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "md_real = (\n",
    "    md_plate\n",
    "# solution-begin\n",
    "    >> gr.cp_marginals(\n",
    "        E=gr.marg_fit(\"lognorm\", df_real.E, floc=0),\n",
    "        mu=gr.marg_fit(\"lognorm\", df_real.mu, floc=0),\n",
    "    )\n",
    "    >> gr.cp_copula_independence()\n",
    "# solution-end\n",
    ")\n",
    "md_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-purpose",
   "metadata": {},
   "source": [
    "# Design Under Uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d937bb-f412-4236-b106-b805fd34465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = gr.df_make(t=0.25, a=12.0, b=9.0, m=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-fortune",
   "metadata": {
    "tags": []
   },
   "source": [
    "### __qX__ Assess a baseline design\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_total = (\n",
    "    md_total\n",
    "# solution-begin\n",
    "    >> gr.ev_sample(n=1e3, df_det=df_baseline)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    "# solution-end\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "assert \\\n",
    "    isinstance(df_baseline_total, pd.DataFrame), \\\n",
    "    \"df_baseline_total is not a DataFrame; make sure to evaluate the model\"\n",
    "assert \\\n",
    "    \"pof_lo\" in df_baseline_total.columns, \\\n",
    "    \"df_baseline_total does not have a pof_lo column; make sure to include a lower CI end\"\n",
    "assert \\\n",
    "    \"pof_up\" in df_baseline_total.columns, \\\n",
    "    \"df_baseline_total does not have a pof_up column; make sure to include a lower CI end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_real = (\n",
    "    md_real\n",
    "# solution-begin\n",
    "    >> gr.ev_sample(n=1e3, df_det=df_baseline)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    "# solution-end\n",
    ")\n",
    "\n",
    "## NOTE: Use this to check your work\n",
    "assert \\\n",
    "    isinstance(df_baseline_real, pd.DataFrame), \\\n",
    "    \"df_baseline_real is not a DataFrame; make sure to evaluate the model\"\n",
    "assert \\\n",
    "    \"pof_lo\" in df_baseline_real.columns, \\\n",
    "    \"df_baseline_real does not have a pof_lo column; make sure to include a lower CI end\"\n",
    "assert \\\n",
    "    \"pof_up\" in df_baseline_real.columns, \\\n",
    "    \"df_baseline_real does not have a pof_up column; make sure to include a lower CI end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_baseline_total\n",
    "    >> gr.tf_mutate(model=\"Total\")\n",
    "    >> gr.tf_bind_rows(\n",
    "        df_baseline_real\n",
    "        >> gr.tf_mutate(model=\"Real\")\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"model\", \"pof\"))\n",
    "    + gr.geom_hline(yintercept=0.01, linetype=\"dashed\")\n",
    "    + gr.geom_errorbar(gr.aes(ymin=\"pof_lo\", ymax=\"pof_up\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdae184-b135-477f-ab9d-745c4d0ab071",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- According to the `Total` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - (Your response here)\n",
    "- According to the `Real` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- According to the `Total` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - No; the `Total` model gives a failure rate somewhere between `0.04` and `0.08`.\n",
    "- According to the `Real` model, does the baseline design meet the desired criteria of `pof < 0.01` (dashed line)?\n",
    "  - Likely no; at a sample size of `n=1e3` the confidence interval for the `Real` model includes the target of `0.01`, but based on the evidence, it is possible that `pof > 0.01`.\n",
    "<!-- solution-end -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c7400-e48e-44b4-8195-0d5b5d614fe7",
   "metadata": {},
   "source": [
    "### __qX__ Adjust the design\n",
    "\n",
    "Adjust the thickness of the plate to *confidently* achieve `pof < 0.01`. Repeat this process for both the `Total` and `Real` models. Answer the questions under *observations* below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a3b9c1-4967-433c-a6e9-d5fa8f9e787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revised_total = gr.df_make(\n",
    "    ## TODO: Adjust the thickness to modify the design\n",
    "# task-begin\n",
    "    # t=0.25,\n",
    "# task-end\n",
    "# solution-begin\n",
    "    t=0.255,\n",
    "# solution-end\n",
    "    ## NOTE: Do not edit the following values\n",
    "    a=12.0, b=9.0, m=1\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit\n",
    "df_revised_total = (\n",
    "    md_total\n",
    "    >> gr.ev_sample(n=1e4, df_det=df_revised_total)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_revised_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a2739d-5a45-49cf-912b-e24748ecf8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_revised_real = gr.df_make(\n",
    "    ## TODO: Adjust the thickness to modify the design\n",
    "# task-begin\n",
    "    # t=0.25,\n",
    "# task-end\n",
    "# solution-begin\n",
    "    t=0.251,\n",
    "# solution-end\n",
    "    ## NOTE: Do not edit the following values\n",
    "    a=12.0, b=9.0, m=1\n",
    ")\n",
    "\n",
    "## NOTE: No need to edit\n",
    "df_revised_real = (\n",
    "    md_real\n",
    "    >> gr.ev_sample(n=1e4, df_det=df_revised_real)\n",
    "    >> gr.tf_summarize(\n",
    "        pof_lo=gr.pr_lo(DF.g_buckle <= 0),\n",
    "        pof=gr.pr(DF.g_buckle <= 0),\n",
    "        pof_up=gr.pr_up(DF.g_buckle <= 0),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_revised_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4a1d0-b78c-4549-bc92-8dcb7a6fbafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: No need to edit; the following visual will help you assess the results\n",
    "(\n",
    "    df_revised_total\n",
    "    >> gr.tf_mutate(model=\"Total\")\n",
    "    >> gr.tf_bind_rows(\n",
    "        df_revised_real\n",
    "        >> gr.tf_mutate(model=\"Real\")\n",
    "    )\n",
    "    \n",
    "    >> gr.ggplot(gr.aes(\"model\", \"pof\"))\n",
    "    + gr.geom_hline(yintercept=0.01, linetype=\"dashed\")\n",
    "    + gr.geom_errorbar(gr.aes(ymin=\"pof_lo\", ymax=\"pof_up\"))\n",
    "    + gr.geom_point()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ada6af-0fc7-430c-8924-f96a7f9ec9f5",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "<!-- task-begin -->\n",
    "- What needs to be the case with your results to *confidently* conclude that `pof < 0.01`?\n",
    "  - (Your response here)\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Total` model?\n",
    "  - (Your response here)\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Real` model?\n",
    "  - (Your response here)\n",
    "- Suppose the plate manufacturing process can only achieve tolerances to within `0.01` in of thickness. Does distinguishing between real and total variability have a large consequence in this case?\n",
    "  - (Your response here)\n",
    "- Now suppose the plate manufacturing process can achieve tolerances to within `0.001` in of thickness, and weight is a major concern. Does distinguishing between real and total variability have a large consequence in this case?\n",
    "  - (Your response here)\n",
    "<!-- task-end -->\n",
    "<!-- solution-begin -->\n",
    "- What needs to be the case with your results to *confidently* conclude that `pof < 0.01`?\n",
    "  - The confidence interval for the POF needs to be entirely below `0.01`.\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Total` model?\n",
    "  - I find `t=0.255`.\n",
    "- What thickness is necessary to confidently achieve `pof < 0.01` with the `Real` model?\n",
    "  - I find `t=0.251`.\n",
    "- Suppose the plate manufacturing process can only achieve tolerances to within `0.01` in of thickness. Does distinguishing between the `Total` and `Real` model assumptions have a large consequence in this case?\n",
    "  - No; both model assumptions would require `t=0.26` to confidently achieve `pof < 0.01.`\n",
    "- Now suppose the plate manufacturing process can achieve tolerances to within `0.001` in of thickness, and weight is a major concern. Does distinguishing between the `Total` and `Real` model assumptions have a large consequence in this case?\n",
    "  - Yes; under the `Real` model we can shave off a bit more weight, leading to a higher-performance design that still achieves the `pof < 0.01` constraint.\n",
    "<!-- solution-end -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
